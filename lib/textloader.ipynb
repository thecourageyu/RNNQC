{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- textloader\n",
    "- date: 2020-08-06\n",
    "- maintainer: YZK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T09:33:35.154772Z",
     "iopub.status.busy": "2020-10-30T09:33:35.154571Z",
     "iopub.status.idle": "2020-10-30T09:33:41.933682Z",
     "shell.execute_reply": "2020-10-30T09:33:41.933239Z",
     "shell.execute_reply.started": "2020-10-30T09:33:35.154750Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# jupyter nbconvert --to script textloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:34:23.102586Z",
     "iopub.status.busy": "2020-10-30T10:34:23.102359Z",
     "iopub.status.idle": "2020-10-30T10:34:23.962893Z",
     "shell.execute_reply": "2020-10-30T10:34:23.962248Z",
     "shell.execute_reply.started": "2020-10-30T10:34:23.102562Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T10:34:23.102586Z",
     "iopub.status.busy": "2020-10-30T10:34:23.102359Z",
     "iopub.status.idle": "2020-10-30T10:34:23.962893Z",
     "shell.execute_reply": "2020-10-30T10:34:23.962248Z",
     "shell.execute_reply.started": "2020-10-30T10:34:23.102562Z"
    }
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import codecs\n",
    "import gc\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "\n",
    "try:\n",
    "    thisd = os.path.dirname(os.path.realpath(__file__))\n",
    "    sys.path.append(thisd)\n",
    "    import widgets as wg\n",
    "    from parallel import runFunctionsInParallel\n",
    "except Exception as E:\n",
    "    if __name__ == \"__main__\":\n",
    "        import msetup\n",
    "        import widgets as wg\n",
    "        from parallel import runFunctionsInParallel        \n",
    "        logd = \"log\"\n",
    "        if not os.path.exists(logd):\n",
    "            os.makedirs(logd)\n",
    "        msetup.setLogging(logf=\"{}/textloader.log\".format(logd), loglv=logging.DEBUG)\n",
    "    else:\n",
    "        import lib.widgets as wg\n",
    "        from lib.parallel import runFunctionsInParallel\n",
    "\n",
    "    logging.warning(E)\n",
    "\n",
    "# print(os.environ['SHELL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build smarker for gridding map (combine all monthly data into one file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T07:43:16.052856Z",
     "iopub.status.busy": "2020-11-03T07:43:16.052619Z",
     "iopub.status.idle": "2020-11-03T07:43:16.073989Z",
     "shell.execute_reply": "2020-11-03T07:43:16.073507Z",
     "shell.execute_reply.started": "2020-11-03T07:43:16.052830Z"
    }
   },
   "outputs": [],
   "source": [
    "def idSelect(stnf, fname=None, key=None, val=None, outf=None):\n",
    "    '''\n",
    "        all2onef: format is the same as smarker\n",
    "    '''\n",
    "    \n",
    "    sinfo = textloader.getGI(stnf, index_col=None)\n",
    "    if fname is not None:\n",
    "        all2onef = pd.read_csv(fname)\n",
    "        all2onef.columns = [\"key\"] + all2onef.columns[1:].tolist()\n",
    "        all2onef.set_index(\"key\", inplace=True)\n",
    "        target = all2onef.loc[key]\n",
    "\n",
    "        ids = sinfo[\"stnid\"]\n",
    "        sinfo.set_index(ids, inplace=True)\n",
    "        sinfo = sinfo.loc[all2onef.columns[target >= val]]\n",
    "\n",
    "        if outf is not None:\n",
    "            sinfo.to_csv(outf, index=False)\n",
    "    else:\n",
    "        sinfo = sinfo.loc[sinfo[\"id\"] == 1]\n",
    "    \n",
    "        if outf is not None:\n",
    "            with open(outf, \"w\") as fid:\n",
    "                fid.write(\"{0:4s} {1:6s} {2:8s} {3:7s} {4:9s} {5:10s} {6:10s} {7:2s} {8}\\n\".format(\"#SN\", \"StnId\", \"Lon\", \"Lat\", \"Elev\", \"t1\", \"t2\", \"Id\", \"StnName\"))\n",
    "                for idx in range(sinfo.shape[0]):\n",
    "                    rc = sinfo.iloc[idx].tolist()\n",
    "                    fid.write(\"{0:04d} {1:6s} {2:8.4f} {3:7.4f} {4:9.4f} {5:10d} {6:10d} {7:2d} {8}\\n\".format(rc[0], rc[1], rc[2], rc[3], rc[4], rc[5], rc[6], rc[7], rc[8]))        \n",
    "    \n",
    "    return sinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T06:06:11.151135Z",
     "iopub.status.busy": "2020-11-02T06:06:11.150928Z",
     "iopub.status.idle": "2020-11-02T06:06:11.178967Z",
     "shell.execute_reply": "2020-11-02T06:06:11.178580Z",
     "shell.execute_reply.started": "2020-11-02T06:06:11.151113Z"
    }
   },
   "outputs": [],
   "source": [
    "def mnf2onef(ind, outf, stnf, tperiod, vname, subd=None, fprefix=\"MONTHLY_\", lb=0, stnkeep=None):\n",
    "    # C1I440 新高口，同時是目標站也是某站之鄰近站，補遺的時候可能沒抓到值（因為id=1或id=2）\n",
    "    \n",
    "    if subd is None:\n",
    "        subd = \"\"\n",
    "    \n",
    "    stninfo = textloader.getGI(stnf)\n",
    "    stnid = stninfo[\"stnid\"].values\n",
    "    \n",
    "    stninfo.set_index(\"stnid\", inplace=True)\n",
    "    \n",
    "    nstn = len(stnid)\n",
    "    syear = tperiod[0]\n",
    "    eyear = tperiod[1]\n",
    "    nyear = eyear - syear + 1\n",
    "    Y = [syear + i for i in range(nyear)]\n",
    "    m = [1 + i for i in range(12)]\n",
    "    \n",
    "    monthly = np.ndarray((nstn, nyear, 12))\n",
    "    monthly.fill(-999)\n",
    "    \n",
    "    dtimes = []\n",
    "    for Y_ in Y:\n",
    "        for m_ in m:\n",
    "            dtimes.append(\"{0:04d}{1:02d}\".format(Y_, m_))\n",
    "    \n",
    "    logs1 = \"mnf2onef: stnid = {}, obs = {} ({}) < {}, cxnid = {}, t1 = {}, t2 = {}\"\n",
    "    for iidx, id_ in enumerate(stnid):\n",
    "        for yidx, Y_ in enumerate(Y):\n",
    "\n",
    "            if len(subd) == 0:\n",
    "                inf = \"{0}/{1}/{2}/{3}{1}_{2}_{4}.txt\".format(ind, vname, Y_, fprefix, id_)\n",
    "            else:\n",
    "                inf = \"{0}/{1}/{2}/{3}/{4}{2}_{3}_{5}.txt\".format(ind, subd, vname, Y_, fprefix, id_)\n",
    "\n",
    "            if os.path.exists(inf):\n",
    "                arr = np.loadtxt(inf, dtype={\"names\": (\"YYYYmm\", \"obs\"), \"formats\": (\"i4\", \"f8\")})\n",
    "                for midx, m_ in enumerate(m):\n",
    "                    Ym = Y_ * 100 + m_\n",
    "                    if arr[midx][0] == Ym:\n",
    "                        if arr[midx][1] < lb and stninfo.loc[stnid[iidx]][\"id\"] == 1:\n",
    "                            logging.warning(logs1.format(stnid[iidx], arr[midx][1], arr[midx][0], lb, \n",
    "                                                         stninfo.loc[stnid[iidx]][\"id\"], stninfo.loc[stnid[iidx]][\"t1\"], stninfo.loc[stnid[iidx]][\"t2\"]))\n",
    "\n",
    "                        monthly[iidx, yidx, midx] = arr[midx][1]\n",
    "            else:\n",
    "                logging.warning(\"{} doesn't exist!\".format(inf))\n",
    "    \n",
    "    outdf = np.vstack([np.reshape(stnid, (1, -1)),\n",
    "                       np.reshape(stninfo[\"lon\"].values, (1, -1)),\n",
    "                       np.reshape(stninfo[\"lat\"].values, (1, -1)),\n",
    "                       np.reshape(stninfo[\"elev\"].values, (1, -1)),\n",
    "                       np.reshape(monthly, (nstn, nyear * 12)).T])\n",
    "    \n",
    "    outdf = pd.DataFrame(outdf)\n",
    "    \n",
    "    idx = [\"stnid\", \"lon\", \"lat\", \"elev\"]\n",
    "    idx.reverse()\n",
    "    for idx_ in idx:\n",
    "        dtimes.insert(0, idx_)\n",
    "    outdf.index = dtimes\n",
    "    outdf.columns = outdf.loc[\"stnid\"]\n",
    "    outdf.drop(index=[\"stnid\"], inplace=True)\n",
    "    \n",
    "#     outdf.to_csv(\"{}/smarker.csv\".format(outd))\n",
    "\n",
    "    if stnkeep is not None:\n",
    "       \n",
    "        stnid = outdf.columns.tolist()\n",
    "        # mnd.drop(index=[\"lon\", \"lat\", \"elev\"], inplace=True)\n",
    "        keepit = [str(i) for i in stnkeep]\n",
    "        dropit = np.setdiff1d(stnid, keepit)\n",
    "        \n",
    "        for i in outdf.index.tolist()[3:]:\n",
    "            outdf.loc[i][dropit] = -999\n",
    "    \n",
    "    \n",
    "    outdf.to_csv(outf)\n",
    "\n",
    "    \n",
    "    return outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T06:16:09.098875Z",
     "iopub.status.busy": "2020-11-02T06:16:09.098668Z",
     "iopub.status.idle": "2020-11-02T06:16:09.284514Z",
     "shell.execute_reply": "2020-11-02T06:16:09.284104Z",
     "shell.execute_reply.started": "2020-11-02T06:16:09.098854Z"
    }
   },
   "outputs": [],
   "source": [
    "class textloader():\n",
    "    def __init__(self, ind, outd=\"output\", logd=\"log\"):\n",
    "        self.ind  = ind\n",
    "        self.outd = outd\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_id(fname):\n",
    "        try:\n",
    "            bincode = codecs.open(fname, mode=\"r\", encoding=\"big5\")  # default encoding='utf-8', unicode transformation format\n",
    "        except Exception as e :\n",
    "#             logging.error(\"textloader-getid-11: \", e)\n",
    "            logging.error(e)\n",
    "            sys.exit(-1)\n",
    "\n",
    "        stnlist_ = pd.read_csv(bincode, sep=\"\\s+\", header=0) \n",
    "        stnlist_.columns = [\"#SN\", \"stnid\", \"lon\", \"lat\", \"elev\", \"t1\", \"t2\", \"id\", \"chname\"]\n",
    "#         return(stnlist_[\"stnid\"].values)\n",
    "        return(stnlist_[\"stnid\"].values.tolist())\n",
    "    \n",
    "    @staticmethod\n",
    "    def getGI(fname, index_col=\"#SN\"):\n",
    "        try:\n",
    "            bincode = codecs.open(fname, mode=\"r\", encoding=\"big5\")  # default encoding='utf-8', unicode transformation format\n",
    "        except Exception as e :\n",
    "            logging.error(e)\n",
    "            sys.exit(-1)\n",
    "\n",
    "        stnlist_ = pd.read_csv(bincode, sep=\"\\s+\", header=0)     \n",
    "        stnlist_.columns = [\"#SN\", \"stnid\", \"lon\", \"lat\", \"elev\", \"t1\", \"t2\", \"id\", \"chname\"]\n",
    "        if index_col is not None:\n",
    "            stnlist_.set_index(index_col, inplace=True)\n",
    "\n",
    "        return(stnlist_)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def cmtval(ind, outd, stnid, syr, eyr, hrfp=\"hr_rr\", mnfp=\"mn_rr\", showarn=True):\n",
    "        '''\n",
    "            calculating cmt val for precp (hourly to monthly)\n",
    "            inf: old hr format, header is stn_id, yyyymmdd, 01, ..., 24\n",
    "            hrfp: prefix of hourly data (input) \n",
    "            mnfp: prefix of monthly data (output)\n",
    "        '''\n",
    "        \n",
    "        mday = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "        \n",
    "        hrfprefix = hrfp\n",
    "        mnfprefix = mnfp \n",
    "\n",
    "        MNDA = np.ndarray((len(stnid), 12), dtype=np.float64)  # monthly data array\n",
    "        NHR  = np.ndarray((len(stnid), 12), dtype=np.int64)    # number of hours in month\n",
    "\n",
    "        MNDA.fill(0.0)\n",
    "        NHR.fill(0)\n",
    "\n",
    "        years = [syr + idx for idx in range(eyr - syr + 1)]\n",
    "\n",
    "        miss_val = []\n",
    "        for idx, id_ in enumerate(stnid):\n",
    "            for YYYY in years:\n",
    "                \n",
    "                fname = \"{0}_{1}_{2}.txt\".format(hrfprefix, str(YYYY), id_)\n",
    "                inf = os.path.join(ind, str(YYYY), fname)\n",
    "\n",
    "                if not os.path.exists(inf):\n",
    "                    if showarn:\n",
    "#                         logging.warning(\"textloader-cmtval-50: {} doesn't exist!\".format(inf))\n",
    "                        logging.warning(\"{} doesn't exist!\".format(inf))\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_csv(inf, header=0, sep=\"\\s+\")\n",
    "                df[\"date\"] = pd.to_datetime(df[\"yyyymmdd\"], format=\"%Y%m%d\")\n",
    "                df.set_index(\"date\", inplace=True)\n",
    "                df.drop([\"stn_id\", \"yyyymmdd\"], axis=1, inplace=True)\n",
    "\n",
    "                fid = open(\"{0}/MON/{1}_{2}_{3}.txt\".format(outd.strip(), mnfprefix, str(YYYY), id_), \"w\")\n",
    "\n",
    "                for mm in range(12):\n",
    "                    fid.write(\"{0:04d}{1:02d} \".format(YYYY, mm + 1))\n",
    "                    t1 = \"{0:04d}{1:02d}01\".format(YYYY, mm + 1)\n",
    "                    t2 = \"{0:04d}{1:02d}{2:02d}\".format(YYYY, mm + 1, mday[mm])\n",
    "                    if df.index[-1].is_leap_year and mm + 1 == 2:  # for February in leap year\n",
    "                        t2 = \"{0:04d}{1:02d}{2:02d}\".format(YYYY, mm + 1, mday[mm] + 1)\n",
    "\n",
    "                    submat = df.loc[t1:t2].values\n",
    "                    missing_idx = np.where(submat < 0)\n",
    "                    submat_ = submat[np.where(submat >= 0)]\n",
    "                    if submat_.size <= 0:\n",
    "                        MNDA[idx, mm] += 0.0\n",
    "                        NHR[idx, mm] += 0\n",
    "                        fid.write(\"{0:>8.1f} {1:>8d}\\n\".format(-999, 0))\n",
    "                    else:\n",
    "                        MNDA[idx, mm] += np.nansum(submat_)\n",
    "                        NHR[idx, mm] += 1\n",
    "                        fid.write(\"{0:>8.1f} {1:>8d}\\n\".format(np.nansum(submat_), submat_.size))\n",
    "\n",
    "                fid.close()\n",
    "\n",
    "                nparr = df.values\n",
    "                miss_val_ = np.unique(nparr[nparr < 0])\n",
    "                for val_ in miss_val_:\n",
    "                    if val_ not in miss_val:\n",
    "                        miss_val.append(val_)\n",
    "\n",
    "        # cmtval output\n",
    "        if not os.path.exists(outd + \"/CV\"):\n",
    "            os.makedirs(outd + \"/CV\")\n",
    "\n",
    "        with open(\"{0}/CV/CV_M_RR.txt\".format(outd.strip()), \"w\") as fid:\n",
    "            fid.write(\"#stnId \")\n",
    "            for mm in range(12):\n",
    "                fid.write(\"      {0:>02d} \".format(mm + 1))\n",
    "            fid.write(\"\\n\")\n",
    "            for idx, id_ in enumerate(stnid): \n",
    "                fid.write(\"{0:6s} \".format(id_))\n",
    "                for mm in range(12):\n",
    "                    if NHR[idx, mm] > 0:\n",
    "                        MNDA[idx, mm] = MNDA[idx, mm] / float(NHR[idx, mm])\n",
    "                    else:\n",
    "                        MNDA[idx, mm] = -999.0\n",
    "                    fid.write(\"{0:>8.1f} \".format(MNDA[idx, mm]))\n",
    "                fid.write(\"\\n\")\n",
    "\n",
    "        with open(\"{0}/CV/NCV_M_RR.txt\".format(outd.strip()), \"w\") as fid:\n",
    "            fid.write(\"#stnId \")\n",
    "            for mm in range(12):\n",
    "                fid.write(\"      {0:>02d} \".format(mm + 1))\n",
    "            fid.write(\"\\n\")\n",
    "            for idx, id_ in enumerate(stnid): \n",
    "                fid.write(\"{0:6s} \".format(id_))\n",
    "                for mm in range(12):\n",
    "                    if NHR[idx, mm] > 0:\n",
    "                        fid.write(\"{0:>8d} \".format(NHR[idx, mm]))\n",
    "                    else:\n",
    "                        fid.write(\"{0:>8d} \".format(-999))\n",
    "                fid.write(\"\\n\")\n",
    "\n",
    "        return [MNDA, NHR, miss_val]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _fdf(fname):\n",
    "#         fname = \"{0}/{1}/{2}_{1}_{3}.txt\".format(ind, YYYY, hrfp, id_)\n",
    "        if not os.path.exists(fname):\n",
    "#             logging.warning(\"textloader-hrf-140: {} doesn't exist!\".format(fname))\n",
    "            logging.warning(\"{} doesn't exist!\".format(fname))\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(fname, header=0, sep=\"\\s+\")\n",
    "        df[\"date\"] = pd.to_datetime(df[\"yyyymmdd\"], format=\"%Y%m%d\")\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        df.drop([\"stn_id\", \"yyyymmdd\"], axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def hrf(ind, stnid, sdtime, edtime, hrfp=\"hr_rr\", lb=0.0):\n",
    "\n",
    "        '''\n",
    "            load hourly data \n",
    "        '''\n",
    "        \n",
    "        syr = math.floor(sdtime / 10**6)\n",
    "        eyr = math.floor(edtime / 10**6)\n",
    "\n",
    "        YYYYmmddHH0000 = wg.YYYYmmddHH0000(syr, eyr, 1)\n",
    "        YYYYmmddHH_ = [math.floor(YmdH / 10**4) for YmdH in YYYYmmddHH0000]\n",
    "\n",
    "        sidx = YYYYmmddHH_.index(sdtime)\n",
    "        eidx = YYYYmmddHH_.index(edtime)\n",
    "        YYYYmmddHH = YYYYmmddHH_[sidx:(eidx + 1)]\n",
    "#         logging.info(\"textloader-hrf-138: sdtime: {}, edtime: {}, nsample: {}\".format(YYYYmmddHH[0], YYYYmmddHH[-1], len(YYYYmmddHH)))\n",
    "        logging.info(\"sdtime: {}, edtime: {}, nsample: {}\".format(YYYYmmddHH[0], YYYYmmddHH[-1], len(YYYYmmddHH)))\n",
    "\n",
    "        \n",
    "        # %%timeit -n 1\n",
    "\n",
    "        nyr = eyr - syr + 1\n",
    "        nstn = len(stnid)\n",
    "        nsample = len(YYYYmmddHH)\n",
    "\n",
    "        \n",
    "        obs_ = np.ndarray(shape=(nstn, nyr, 366, 24))  # datetime to array index, don't use datetime to search index in YYYYmmddHH (not efficient)\n",
    "        obs_.fill(-999)\n",
    "        \n",
    "        obs = np.ndarray(shape=(nstn, nsample))\n",
    "        obs.fill(-999)\n",
    "\n",
    "        years = [syr + i for i in range(nyr)]\n",
    "\n",
    "        for ididx, id_ in enumerate(stnid):\n",
    "#             dfs = []\n",
    "            for yidx, YYYY in enumerate(years):\n",
    "                fname = \"{0}/{1}/{2}_{1}_{3}.txt\".format(ind, YYYY, hrfp, id_)\n",
    "                if not os.path.exists(fname):\n",
    "                    logging.warning(\"textloader-hrf-156: {} doesn't exist!\".format(fname))\n",
    "                    logging.warning(\"{} doesn't exist!\".format(fname))\n",
    "                    continue\n",
    "\n",
    "                df = pd.read_csv(fname, header=0, sep=\"\\s+\")\n",
    "#                 df[\"date\"] = pd.to_datetime(df[\"yyyymmdd\"], format=\"%Y%m%d\")\n",
    "                df[\"date\"] = df[\"yyyymmdd\"]\n",
    "\n",
    "                df.set_index(\"date\", inplace=True)\n",
    "\n",
    "                df.drop([\"stn_id\", \"yyyymmdd\"], axis=1, inplace=True)\n",
    "#                 dfs.append(df)\n",
    "\n",
    "#                 dtimes = df.index.values\n",
    "                dtimes = df.index.tolist()\n",
    "\n",
    "                for dtime in dtimes:\n",
    "                  \n",
    "                    Y_, m_, d_, H_ = wg.datetime_split(dtime, hour_system=1) \n",
    "\n",
    "                    for H_ in range(24):\n",
    "                        ttuple = datetime.strptime(\"{0:04d}{1:02d}{2:02d}\".format(Y_, m_, d_), \"%Y%m%d\").timetuple()\n",
    "#                         logging.debug(\"hrf-209: {0}, {1:04d}-{2:02d}-{3:02d} {4:02d}:00:00\".format(dtime, Y_, m_, d_, H_))\n",
    "                        obs_[ididx, yidx, ttuple[7] - 1, H_] = df.loc[dtime][H_]\n",
    "                    \n",
    "            # reshape\n",
    "            idx = 0\n",
    "            dtidx = 0\n",
    "            for yidx, YYYY in enumerate(years):\n",
    "                yday = 365\n",
    "                if calendar.isleap(YYYY):\n",
    "                    yday += 1\n",
    "#                 logging.debug(\"hrf-219: check yday={0}, dtidx={1}\".format(yday, dtidx))\n",
    "                logging.debug(\"check yday={0}, dtidx={1}\".format(yday, dtidx))\n",
    "\n",
    "                for didx in range(yday):\n",
    "                    for hidx in range(24):\n",
    "                        YmdH = YYYYmmddHH_[idx]\n",
    "                        idx += 1\n",
    "                        if YYYYmmddHH[0] <= YmdH and YmdH <= YYYYmmddHH[-1]:\n",
    "                            obs[ididx, dtidx] = obs_[ididx, yidx, didx, hidx]\n",
    "                            dtidx += 1\n",
    "\n",
    "                             \n",
    "#             if len(dfs) == 0:\n",
    "#                 continue\n",
    "\n",
    "#             df = pd.concat(dfs, axis=0)\n",
    "\n",
    "#             dtidx = 0\n",
    "#             for YmdH in YYYYmmddHH:\n",
    "#                 Ymd = math.floor(YmdH / 100.0)\n",
    "#                 HH = YmdH - Ymd * 100 - 1\n",
    "#                 obs[ididx, dtidx] = df.loc[str(Ymd)][HH]\n",
    "#                 dtidx += 1\n",
    "\n",
    "        quantity = np.where(obs >= lb)[0].shape[0] / obs.size\n",
    "\n",
    "#         logging.info(\"textloader-hrf-quantity: {}\".format(quantity))\n",
    "        logging.info(\"hrf-quantity = {}\".format(quantity))\n",
    "\n",
    "        return [obs, stnid, YYYYmmddHH, quantity]\n",
    "    \n",
    "    @staticmethod\n",
    "    def mnf(inf, stnid, sdtime, edtime, vname=\"VNAME\", outd=None, cvd=None, lb=0.0, nmn=10, ftype='dbout'):\n",
    "\n",
    "        '''\n",
    "            load monthly data \"db_data_{vname}.txt and \n",
    "                (1) reformat it to \"{outd}/MON/{YYYY}/MONTHLY_{vname}_{YYYY}_{id_}.txt\" if {outd} is not None\n",
    "                (2) calculate cmt val and output to {cvd} if {cvd} is not None\n",
    "                \n",
    "            ftype: \n",
    "                \"dbout\": output of get_data.py, all data in one \n",
    "                \"smarker\": indexes include lon, lat, elev, datetime, and columns are stations\n",
    "        '''\n",
    "        \n",
    "        syr  = math.floor(sdtime / 10**2)\n",
    "        eyr  = math.floor(edtime / 10**2)\n",
    "        nyr  = eyr - syr + 1\n",
    "        nstn = len(stnid)\n",
    "\n",
    "        YYYYmm_ = wg.YYYYmm(syr, eyr)\n",
    "        sidx = YYYYmm_.index(sdtime)\n",
    "        eidx = YYYYmm_.index(edtime)\n",
    "        YYYYmm = YYYYmm_[sidx:(eidx + 1)]\n",
    "        nsample = len(YYYYmm)\n",
    "\n",
    "        # ndarray declare\n",
    "        cv = np.ndarray((nstn, nyr, 12))\n",
    "        cv.fill(-999)\n",
    "\n",
    "        obs = np.ndarray((nstn, nsample))\n",
    "        obs.fill(-999)\n",
    "\n",
    "        # load db data\n",
    "        if ftype == \"smarker\":\n",
    "            df = pd.read_csv(inf, header=0)\n",
    "            df.columns = [\"datetime\"] + df.columns.tolist()[1:]\n",
    "            df.set_index(\"datetime\", inplace=True)\n",
    "            gi = df.iloc[0:3]\n",
    "            df.drop(index=[\"lon\", \"lat\", \"elev\"], inplace=True)\n",
    "            df.index = [int(i) for i in df.index.to_list()]\n",
    "        else:\n",
    "            df = pd.read_csv(inf, sep=\"\\s+\", header=0)\n",
    "            df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "        dfdt = df.index.to_list()\n",
    "        sidx = dfdt.index(sdtime)\n",
    "        eidx = dfdt.index(edtime)\n",
    "\n",
    "        for ididx, id_ in enumerate(stnid):\n",
    "            if id_ in df.columns:\n",
    "                obs[ididx, :] = df[id_].values[sidx:(eidx + 1)]\n",
    "                for Ym in YYYYmm:\n",
    "                    Y_ = math.floor(Ym / 100.0)\n",
    "                    m_ = Ym - Y_ * 100\n",
    "                    idx = dfdt.index(Ym)\n",
    "                    cv[ididx, Y_ - syr, m_ - 1] = df.loc[Ym][id_]\n",
    "        \n",
    "        if outd is not None:\n",
    "            for yridx in range(nyr):\n",
    "                Y_ = syr + yridx\n",
    "                \n",
    "                if not os.path.exists(\"{}/MON/{}/{}\".format(outd, vname, Y_)):\n",
    "                    os.makedirs(\"{}/MON/{}/{}\".format(outd, vname, Y_))\n",
    "                \n",
    "                for ididx, id_ in enumerate(stnid):\n",
    "                    with open(\"{0}/MON/{1}/{2}/MONTHLY_{1}_{2}_{3}.txt\".format(outd, vname, Y_, id_), \"w\") as fid:\n",
    "                        for m_ in range(12):\n",
    "                            fid.write(\"{0:04d}{1:02d}{2:9.1f}\\n\".format(Y_, m_ + 1, cv[ididx, yridx, m_]))\n",
    "\n",
    "        if cvd is not None:\n",
    "            cv[np.where(cv < lb)] = np.nan\n",
    "            cmt_val = np.ndarray((nstn, 12))\n",
    "            cmt_val.fill(-999)\n",
    "            mncounter = np.zeros((nstn, 12), dtype=np.int32)\n",
    "            for ididx in range(nstn):\n",
    "                cmt_val[ididx, :] = np.nanmean(cv[ididx, :, :], axis=0)\n",
    "                mncounter[ididx, :] = (~np.isnan(cv[ididx, :, :])).sum(axis=0)\n",
    "\n",
    "            cmt_val[np.isnan(cmt_val)] = -999\n",
    "\n",
    "            cmt_val[np.where(mncounter < nmn)] = -999\n",
    "            \n",
    "            if not os.path.exists(cvd):\n",
    "                os.makedirs(cvd)\n",
    "\n",
    "            cvfid  = open(\"{0}/CV_MN_{1}.txt\".format(cvd, vname), \"w\")\n",
    "            ncvfid = open(\"{0}/NCV_MN_{1}.txt\".format(cvd, vname), \"w\")\n",
    "\n",
    "            cvfid.write(\"#stnId\")\n",
    "            ncvfid.write(\"#stnId\")\n",
    "            if ftype == \"smarker\":\n",
    "                cvfid.write(\"{0:>12s}\".format(\"lon\"))\n",
    "                cvfid.write(\"{0:>12s}\".format(\"lat\"))\n",
    "                cvfid.write(\"{0:>12s}\".format(\"elev\"))\n",
    "\n",
    "            for mnidx in range(12):\n",
    "                cvfid.write(\"{0:7s}{1:02d}\".format(\" \", mnidx + 1))\n",
    "                ncvfid.write(\"{0:7s}{1:02d}\".format(\" \", mnidx + 1))\n",
    "            cvfid.write(\"\\n\")\n",
    "            ncvfid.write(\"\\n\")\n",
    "\n",
    "            for ididx in range(nstn):\n",
    "                cvfid.write(stnid[ididx])\n",
    "                if ftype == \"smarker\":\n",
    "                    cvfid.write(\"{0:12.4f}\".format(gi.iloc[0][stnid[ididx]]))\n",
    "                    cvfid.write(\"{0:12.4f}\".format(gi.iloc[1][stnid[ididx]]))\n",
    "                    cvfid.write(\"{0:12.4f}\".format(gi.iloc[2][stnid[ididx]]))\n",
    "                ncvfid.write(stnid[ididx])\n",
    "                \n",
    "                for mnidx in range(12):\n",
    "                    cvfid.write(\"{0:9.1f}\".format(cmt_val[ididx, mnidx]))\n",
    "                    ncvfid.write(\"{0:9d}\".format(mncounter[ididx, mnidx]))\n",
    "                cvfid.write(\"\\n\")\n",
    "                ncvfid.write(\"\\n\")\n",
    "\n",
    "            cvfid.close()\n",
    "            ncvfid.close()\n",
    "\n",
    "        quantity = np.where(obs >= lb)[0].shape[0] / obs.size\n",
    "\n",
    "        logging.info(\"mnf-quantity = {}\".format(quantity))\n",
    "\n",
    "        return [obs, stnid, YYYYmm, quantity]\n",
    "\n",
    "    @staticmethod\n",
    "    def floader(fname, nvar, qkey=None):\n",
    "        df = pd.read_csv(fname, sep=\"\\s+\", header=None)\n",
    "        if nvar == 3:\n",
    "            df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\", \"thmval\"]\n",
    "        else:\n",
    "            df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\"]\n",
    "        df.set_index(\"id\", inplace=True)\n",
    "        \n",
    "        return [df, qkey]\n",
    "        \n",
    "    @staticmethod\n",
    "    def ossef(ind, stnid, nvar, syr, eyr, fprefix=\"OSSE_\", **kwargs):\n",
    "\n",
    "        '''\n",
    "            load output of osse for hourly, daily and monthly data\n",
    "            nvar: 3 for obs, est and thmval and 2 for obs and est\n",
    "        '''\n",
    "\n",
    "        nyr = eyr - syr + 1\n",
    "        Ymd = wg.YYYYmmdd(syr, eyr)\n",
    "        ndt = len(Ymd)\n",
    "        nstn = len(stnid)\n",
    "\n",
    "        HH = [1 + i for i in range(24)]\n",
    "        YYYY = [syr + i for i in range(nyr)]\n",
    "\n",
    "        osseH = np.ndarray((24, 366, nyr, nstn, nvar))\n",
    "        osseH.fill(-999)\n",
    "        logging.info(\"load osse for hourly data\")\n",
    "        jobs = []\n",
    "        YmdHs = []\n",
    "        for dt_idx, Ymd_ in enumerate(Ymd):\n",
    "#             dtuple = datetime.strptime(str(Ymd_), \"%Y%m%d\").timetuple()\n",
    "#             Y_ = dtuple[0] \n",
    "#             M_ = dtuple[1]\n",
    "#             wday = dtuple[6]\n",
    "            wg.display_progress(dt_idx, ndt, 2)\n",
    "            for H_ in HH:\n",
    "#                 df = pd.read_csv(\"{0}/{1}{2}{3:02d}.txt\".format(ind, fprefix, Ymd_, H_), sep=\"\\s+\", header=None)\n",
    "#                 if nvar == 3:\n",
    "#                     df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\", \"thmval\"]\n",
    "#                 else:\n",
    "#                     df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\"]\n",
    "#                 df.set_index(\"id\", inplace=True)\n",
    "#                 for id_idx, id_ in enumerate(stnid):\n",
    "#                     osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 0] = df.loc[id_][\"obs\"]\n",
    "#                     osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 1] = df.loc[id_][\"est\"]\n",
    "#                     if nvar == 3:\n",
    "#                         osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 2] = df.loc[id_][\"thmval\"]\n",
    "\n",
    "                YmdHs.append(Ymd_ * 100 + H_)\n",
    "                jobs.append([textloader.floader, [\"{0}/{1}{2}{3:02d}.txt\".format(ind, fprefix, Ymd_, H_), nvar, YmdHs[-1]]])\n",
    "                \n",
    "        ret = runFunctionsInParallel(jobs, names=[str(i) for i in YmdHs],\n",
    "                                     offsetsSeconds=0.2, parallel=True, allowJobFailure=True)\n",
    "        \n",
    "        for jidx in range(len(YmdHs)):\n",
    "            df = ret[1][jidx][0]\n",
    "            qkey = ret[1][jidx][1]  # datetime, YYYYmmddHH\n",
    "            logging.info(\"queue for {}\".format(qkey))\n",
    "            Ymd_ = str(qkey)[0:-2]\n",
    "            H_ = int(str(qkey)[-2:])\n",
    "            dtuple = datetime.strptime(Ymd_, \"%Y%m%d\").timetuple()\n",
    "            Y_ = dtuple[0] \n",
    "            M_ = dtuple[1]\n",
    "#             H_ = dtuple[3]\n",
    "            wday = dtuple[7]            \n",
    "            for id_idx, id_ in enumerate(stnid):\n",
    "                osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 0] = df.loc[id_][\"obs\"]\n",
    "                osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 1] = df.loc[id_][\"est\"]\n",
    "                if nvar == 3:\n",
    "                    osseH[H_ - 1, wday - 1, Y_ - syr, id_idx, 2] = df.loc[id_][\"thmval\"]\n",
    "\n",
    "        gc.collect()        \n",
    "\n",
    "                    \n",
    "        osseD = np.ndarray((366, nyr, nstn, nvar))\n",
    "        osseD.fill(-999)\n",
    "        logging.info(\"load osse for daily data\")\n",
    "        Ymds = []\n",
    "        for dt_idx, Ymd_ in enumerate(Ymd):\n",
    "            Ymds.append(Ymd_)\n",
    "            dtuple = datetime.strptime(str(Ymd_), \"%Y%m%d\").timetuple()\n",
    "            Y_ = dtuple[0] \n",
    "            M_ = dtuple[1]\n",
    "            wday = dtuple[7]\n",
    "            wg.display_progress(dt_idx, ndt, 2)\n",
    "            df = pd.read_csv(\"{0}/{1}{2}.txt\".format(ind, fprefix, Ymd_), sep=\"\\s+\", header=None)\n",
    "            if nvar == 3:\n",
    "                df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\", \"thmval\"]\n",
    "            else:\n",
    "                df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\"]\n",
    "            df.set_index(\"id\", inplace=True)\n",
    "            for id_idx, id_ in enumerate(stnid):\n",
    "                osseD[wday - 1, Y_ - syr, id_idx, 0] = df.loc[id_][\"obs\"]\n",
    "                osseD[wday - 1, Y_ - syr, id_idx, 1] = df.loc[id_][\"est\"]\n",
    "                if nvar == 3:\n",
    "                    osseD[wday - 1, Y_ - syr, id_idx, 2] = df.loc[id_][\"thmval\"]\n",
    "\n",
    "        gc.collect()        \n",
    "\n",
    "                    \n",
    "        osseM = np.ndarray((12, nyr, nstn, nvar))\n",
    "        osseM.fill(-999)\n",
    "        lcounter = 0  # for progress display\n",
    "        logging.info(\"load osse for monthly data\")\n",
    "        Yms = []\n",
    "        for yr_idx, Y_ in enumerate(YYYY):\n",
    "            for m_ in range(12):\n",
    "                Yms.append(Y_ * 100 + m_ + 1)\n",
    "                wg.display_progress(lcounter, nyr * 12, 2)\n",
    "                lcounter += 1\n",
    "                df = pd.read_csv(\"{0}/{1}{2}{3:02d}.txt\".format(ind, fprefix, Y_, m_ + 1), sep=\"\\s+\", header=None)\n",
    "                if nvar == 3:\n",
    "                    df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\", \"thmval\"]\n",
    "                else:\n",
    "                    df.columns = [\"id\", \"lon\", \"lat\", \"elev\", \"obs\", \"est\"]\n",
    "                df.set_index(\"id\", inplace=True)\n",
    "                for id_idx, id_ in enumerate(stnid):\n",
    "                    osseM[m_, yr_idx, id_idx, 0] = df.loc[id_][\"obs\"]\n",
    "                    osseM[m_, yr_idx, id_idx, 1] = df.loc[id_][\"est\"]\n",
    "                    if nvar == 3:\n",
    "                        osseM[m_, yr_idx, id_idx, 2] = df.loc[id_][\"thmval\"]\n",
    "\n",
    "        gc.collect()        \n",
    "\n",
    "                        \n",
    "        return [osseH, osseD, osseM, YmdHs, Ymds, Yms]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# staticmethod test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T04:13:42.199914Z",
     "iopub.status.busy": "2020-11-06T04:13:42.199703Z",
     "iopub.status.idle": "2020-11-06T04:13:42.247613Z",
     "shell.execute_reply": "2020-11-06T04:13:42.247146Z",
     "shell.execute_reply.started": "2020-11-06T04:13:42.199890Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "#     logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    targetf = \"cmtval\"\n",
    "#     targetf = \"ossef\"\n",
    "    targetf = \"dec2anls\"\n",
    "    \n",
    "    if targetf == \"hr2mn\":\n",
    "        ind     = \"/NAS-129/users1/T1/DATA/YY/ORG/HR1/RR\"\n",
    "        outd    = \"/NAS-129/users1/T1/DATA/YY/ORG\"\n",
    "        stninfo = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/RR_analysis_grid_stationlist.txt\"\n",
    "        fprefix = \"hr_rr\"\n",
    "        syr = 1998\n",
    "        eyr = 2018\n",
    "        # stnid = textloader.get_id(stninfo)\n",
    "        # MNDA, NHR, miss_val = textloader.cmtval(ind, outd, stnid, syr, eyr, hrfp=fprefix, showarn=False)\n",
    "    elif targetf == \"cmtval\":\n",
    "        # load monthly data (format: all in one) and calculate climate values\n",
    "        stninfo = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/RR_analysis_grid_stationlist.txt\"\n",
    "    #     inf = \"/NAS-129/users1/T1/DATA/YY/ORG/MON/db_data_Precp.txt\"\n",
    "    #     inf = \"/NAS-129/users1/T1/DATA/YY/ORG/MON/Precp_1981_2019.txt\"\n",
    "    #     outd = '/NAS-129/users1/T1/DATA/YY/ORG'\n",
    "\n",
    "        stnid = textloader.get_id(stninfo)\n",
    "\n",
    "        # cvd=None, get monthly data (1981 ~ 1997, 1998 ~ 2019 will be replace by using preprocessing data)\n",
    "        sdtime = 198101\n",
    "        edtime = 201912\n",
    "        inf = \"/NAS-129/users1/T1/DATA/YY/CXN/MON/Precp_1981_2019.txt\"  # use ORG with CXN procedure\n",
    "        outd = '/NAS-129/users1/T1/DATA/YY/CXN' \n",
    "        obs, stnid, YYYYmm, quantity = textloader.mnf(inf, stnid, sdtime=sdtime, edtime=edtime, vname=\"RR\", outd=outd, cvd=None, lb=0.0)\n",
    "\n",
    "        # get cmt val and replace monthly data (1998 ~ 2019)\n",
    "        sdtime = 199801\n",
    "        edtime = 201812\n",
    "        cvd = '/NAS-129/users1/T1/DATA/YY/ORG/CV'  # 1998 ~ 2018\n",
    "        inf = \"/NAS-129/users1/T1/DATA/Preprocess/MON/RR/smarker.csv\"\n",
    "        outd = '/NAS-129/users1/T1/DATA/YY/CXN'\n",
    "        obs, stnid, YYYYmm, quantity = textloader.mnf(inf, stnid, sdtime=sdtime, edtime=edtime, vname=\"RR\", outd=outd, cvd=cvd, lb=0.0, ftype=\"smarker\")\n",
    "                \n",
    "    elif targetf == \"hrf\":\n",
    "        ind = \"/NAS-129/users1/T1/DATA/YY/ORG/HR1/RR\"\n",
    "        sdtime = 1998010101\n",
    "        edtime = 1999013124\n",
    "        hrfp = \"hr_rr\"\n",
    "        stnid = textloader.get_id(stninfo)\n",
    "    #     obs, stnid, YYYYmmddHH, quantity = textloader.hrf(ind, stnid, sdtime=sdtime, edtime=edtime, hrfp=hrfp)\n",
    "    elif targetf == \"ossef\":\n",
    "        wg.get_pentad(20120302, 123)    \n",
    "        ind = \"/NAS-129/users1/T1/DATA/GRD/OSSE/UNC/OSSE/PP\"\n",
    "        gid = \"/NAS-129/users1/T1/DATA/YY/GI/PP_analysis_grid_stationlist.txt\"\n",
    "        syr = 1998\n",
    "        eyr = 2017\n",
    "        nvar = 3\n",
    "        stnid = textloader.get_id(gid)\n",
    "        osseH, osseD, osseM = textloader.ossef(ind, stnid, nvar, 2011, 2013)\n",
    "    \n",
    "    elif targetf == \"idSelet\":\n",
    "        stnf = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/RR_analysis_grid_stationlist.txt\"\n",
    "        fname = \"/NAS-129/users1/T1/DATA/YY/CXN/MON/RR/smarker.csv\" \n",
    "        idSelect(stnf, fname, key=\"198101\", val=0, outf=\"sinfo1981.txt\")\n",
    "        \n",
    "    elif targetf == \"dec2anls\":\n",
    "        stnf = \"/NAS-129/users1/T1/DATA/YY/GI/RH_decode_grid_stationlist_2012_2019.txt\"\n",
    "        sinfo = idSelect(stnf, outf=\"/NAS-129/users1/T1/DATA/YY/GI/RH_analysis_grid_stationlist_2012_2019.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T07:34:15.885273Z",
     "iopub.status.busy": "2020-11-03T07:34:15.885066Z",
     "iopub.status.idle": "2020-11-03T07:34:15.900486Z",
     "shell.execute_reply": "2020-11-03T07:34:15.900080Z",
     "shell.execute_reply.started": "2020-11-03T07:34:15.885250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "466880\n",
      "121.4421\n",
      "24.9976\n",
      "9.7\n",
      "2002010101\n",
      "2019123199\n",
      "1\n",
      "ChineseName\n"
     ]
    }
   ],
   "source": [
    "for i in sinfo.iloc[0].tolist():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T07:39:10.924687Z",
     "iopub.status.busy": "2020-11-03T07:39:10.924480Z",
     "iopub.status.idle": "2020-11-03T07:39:11.000027Z",
     "shell.execute_reply": "2020-11-03T07:39:10.999585Z",
     "shell.execute_reply.started": "2020-11-03T07:39:10.924664Z"
    }
   },
   "outputs": [],
   "source": [
    "sinfo\n",
    "# 0001 466900 121.4489 25.1649   19.0000 1911010101 2018051099 1 淡水\n",
    "\n",
    "with open(\"test.txt\", \"w\") as fid:\n",
    "    fid.write(\"{0:4s} {1:6s} {2:8s} {3:7s} {4:9s} {5:10s} {6:10s} {7:2s} {8}\\n\".format(\"#SN\", \"stnid\", \"lon\", \"lat\", \"elev\", \"t1\", \"t2\", \"id\", \"chname\"))\n",
    "    for idx in range(sinfo.shape[0]):\n",
    "        rc = sinfo.iloc[idx].tolist()\n",
    "        fid.write(\"{0:04d} {1:6s} {2:8.4f} {3:7.4f} {4:9.4f} {5:10d} {6:10d} {7:2d} {8}\\n\".format(rc[0], rc[1], rc[2], rc[3], rc[4], rc[5], rc[6], rc[7], rc[8]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build smarker for gridding map (combine all monthly data into one file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T06:06:25.094267Z",
     "iopub.status.busy": "2020-11-02T06:06:25.094067Z",
     "iopub.status.idle": "2020-11-02T06:06:30.327410Z",
     "shell.execute_reply": "2020-11-02T06:06:30.326992Z",
     "shell.execute_reply.started": "2020-11-02T06:06:25.094246Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    stnf = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/RR_analysis_grid_stationlist.txt\"\n",
    "    vname = \"RR\"\n",
    "\n",
    "#     stnkeep = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI\n",
    "    stnkeepf = \"/NAS-129/users1/T1/DATA/YY/GI/sinfo1981.txt\"\n",
    "    stnkeep = pd.read_csv(stnkeepf, header=0)\n",
    "    stnkeep = stnkeep[\"stnid\"].tolist()\n",
    "    \n",
    "    # condition\n",
    "    smarkerf = \"GConsistency\"\n",
    "#     smarkerf = \"GTraceback\"\n",
    "\n",
    "    if smarkerf == \"GConsistency\":\n",
    "        ind = \"/NAS-129/users1/T1/DATA/Preprocess/MON\"\n",
    "        tperiod = [1998, 2019]\n",
    "\n",
    "    elif smarkerf == \"GTraceback\":\n",
    "#         ind = \"/NAS-129/users1/T1/DATA/YY/ORG/MON\"\n",
    "        ind = \"/NAS-129/users1/T1/DATA/YY/CXN/MON\"\n",
    "        tperiod = [1981, 1997]\n",
    "    \n",
    "    outf = \"{}/{}/smarker.csv\".format(ind, vname)\n",
    "    mnd = mnf2onef(ind, outf, stnf, tperiod, vname)\n",
    "    \n",
    "#     outf = \"{}/{}/smarker.csv\".format(ind, vname)\n",
    "#     mnd = mnf2onef(ind, outf, stnf, tperiod, vname, stnkeep=stnkeep)\n",
    "#     mnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

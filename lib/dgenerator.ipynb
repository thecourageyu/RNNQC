{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dgenerator\n",
    "- import modules: \n",
    " 1. mdfloader\n",
    " 2. textloader \n",
    " 3. parallel\n",
    "- date: 2020-08-06\n",
    "- maintainer: YZK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# jupyter nbconvert --to script dgenerator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T01:55:19.801708Z",
     "iopub.status.busy": "2021-03-16T01:55:19.801480Z",
     "iopub.status.idle": "2021-03-16T01:55:19.900727Z",
     "shell.execute_reply": "2021-03-16T01:55:19.900244Z",
     "shell.execute_reply.started": "2021-03-16T01:55:19.801684Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T02:38:06.386606Z",
     "iopub.status.busy": "2021-03-16T02:38:06.386323Z",
     "iopub.status.idle": "2021-03-16T02:38:06.406396Z",
     "shell.execute_reply": "2021-03-16T02:38:06.405927Z",
     "shell.execute_reply.started": "2021-03-16T02:38:06.386578Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:name '__file__' is not defined\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "try:\n",
    "    thisd = os.path.dirname(os.path.realpath(__file__))\n",
    "    sys.path.append(thisd)\n",
    "    from mdfloader import Dataset\n",
    "    from parallel import runFunctionsInParallel\n",
    "    from textloader import textloader \n",
    "except Exception as E:\n",
    "    logging.warning(E)\n",
    "    if __name__ == \"__main__\":\n",
    "        import msetup\n",
    "        from mdfloader import Dataset\n",
    "        from parallel import runFunctionsInParallel\n",
    "        from textloader import textloader    \n",
    "    else:\n",
    "        from lib.mdfloader import Dataset\n",
    "        from lib.parallel import runFunctionsInParallel\n",
    "        from lib.textloader import textloader\n",
    "\n",
    "floader   = Dataset.floader\n",
    "getGI     = Dataset.getGI\n",
    "qcfparser = Dataset.qcfparser\n",
    "getids    = textloader.get_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T02:38:07.164412Z",
     "iopub.status.busy": "2021-03-16T02:38:07.164171Z",
     "iopub.status.idle": "2021-03-16T02:38:07.185924Z",
     "shell.execute_reply": "2021-03-16T02:38:07.185505Z",
     "shell.execute_reply.started": "2021-03-16T02:38:07.164387Z"
    }
   },
   "outputs": [],
   "source": [
    "def dtimeGenerator(tperiod, fmt):\n",
    "    \n",
    "    '''\n",
    "        tperiod: [sdtime, edtime]\n",
    "        fmt: \"Ymd\", \"YmdH\", \"YmdHM\"\n",
    "        hour system: 00 ~ 23\n",
    "        return dtimes and idx2posi (is an int array)\n",
    "    '''\n",
    "    \n",
    "    sdtime = datetime.strptime(str(tperiod[0]), fmt) \n",
    "    edtime = datetime.strptime(str(tperiod[1]), fmt)\n",
    "    _dtime = sdtime\n",
    "    dtimes = []\n",
    "    \n",
    "    syr = sdtime.timetuple()[0]\n",
    "    eyr = edtime.timetuple()[0]\n",
    "    nyr = eyr - syr + 1\n",
    "    \n",
    "    if fmt == \"%Y%m%d\":\n",
    "        idx2posi = np.ndarray((nyr, 366), dtype=np.int16)\n",
    "    elif fmt == \"%Y%m%d%H\":\n",
    "        idx2posi = np.ndarray((nyr, 366, 24), dtype=np.int16)\n",
    "    elif fmt == \"%Y%m%d%H%M\":\n",
    "        idx2posi = np.ndarray((nyr, 366, 24, 6), dtype=np.int16)\n",
    "\n",
    "    idx2posi.fill(-999)\n",
    "    \n",
    "    posi = 0\n",
    "    while _dtime <= edtime:\n",
    "        ttuple = _dtime.timetuple()\n",
    "        dtimes.append(_dtime)\n",
    "        if fmt == \"%Y%m%d\":\n",
    "            _dtime += timedelta(days=1)\n",
    "            idx2posi[ttuple[0] - syr, ttuple[7] - 1] = posi\n",
    "        elif fmt == \"%Y%m%d%H\":\n",
    "            _dtime += timedelta(hours=1)\n",
    "            idx2posi[ttuple[0] - syr, ttuple[7] - 1, ttuple[3] - 1] = posi\n",
    "        elif fmt == \"%Y%m%d%H%M\":\n",
    "            _dtime += timedelta(minutes=10)\n",
    "            idx2posi[ttuple[0] - syr, ttuple[7] - 1, ttuple[3] - 1, int(ttuple[4] * 0.1)] = posi\n",
    "\n",
    "        posi += 1\n",
    "            \n",
    "    return dtimes, idx2posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T02:38:08.953433Z",
     "iopub.status.busy": "2021-03-16T02:38:08.953210Z",
     "iopub.status.idle": "2021-03-16T02:38:09.068233Z",
     "shell.execute_reply": "2021-03-16T02:38:09.067715Z",
     "shell.execute_reply.started": "2021-03-16T02:38:08.953411Z"
    }
   },
   "outputs": [],
   "source": [
    "class dgenerator():\n",
    "    def __init__(self, \n",
    "                 resd=None, \n",
    "                 ind=None, cmpltd=None, parsed=None, \n",
    "                 npyd=None,\n",
    "                 vrange=None,\n",
    "                 gif=\"stations.txt\",\n",
    "                 cwbfmt=\".QPESUMS_STATION.10M.mdf\",\n",
    "                 autofmt=\".QPESUMS_STATION.15M.mdf\",\n",
    "                 pfmt=\".QPESUMS_STATION.txt\"):\n",
    "        \n",
    "        self.ind     = ind\n",
    "        self.cmpltd  = cmpltd\n",
    "        self.parsed  = parsed\n",
    "        self.npyd    = npyd\n",
    "        self.cwbfmt  = cwbfmt\n",
    "        self.autofmt = autofmt\n",
    "        self.pfmt    = pfmt        \n",
    "        self.stnids  = None\n",
    "        self.nstn    = None\n",
    "        \n",
    "        if vrange is None:\n",
    "            vrange = {\"Temp\": [-20.0, 50.0],\n",
    "                      \"RH\": [0.0, 100.0],\n",
    "                      \"Pres\": [600.0, 1100.0],\n",
    "                      \"Precp\": [0.0, 220.0]}\n",
    "    \n",
    "        self.vrange = pd.DataFrame(vrange)\n",
    "            \n",
    "#         self.vnames = [\"Temp\", \"RH\", \"Pres\", \"Precp\"]\n",
    "        self.vnames = self.vrange.columns.to_list()\n",
    "        \n",
    "        self.vname2abbr = {\"Temp\": \"TT\", \n",
    "                           \"RH\": \"RH\", \n",
    "                           \"Pres\": \"PP\", \n",
    "                           \"Precp\": \"RR\"}\n",
    "        \n",
    "        if resd is not None:\n",
    "            try:\n",
    "                self.raw_gi, self.stnids, self.nstn = getGI(\"{0}/{1}\".format(resd, gif))\n",
    "            except Exception as E:\n",
    "                logging.warning(\"{}\".format(E))\n",
    "                self.stnids = getids(\"{0}/{1}\".format(resd, gif))\n",
    "                self.nstn   = len(self.stnids)\n",
    "        else:\n",
    "            try:\n",
    "                self.stnids = getids(\"{0}\".format(gif))\n",
    "                self.nstn   = len(self.stnids)\n",
    "            except Exception as E:\n",
    "                logging.warning(\"{}\".format(E))\n",
    "                self.raw_gi, self.stnids, self.nstn = getGI(\"{}\".format(gif))\n",
    "        \n",
    "    @property\n",
    "    def stnids(self):    \n",
    "        return self._stnids\n",
    "        \n",
    "    @stnids.setter\n",
    "    def stnids(self, val):\n",
    "        self._stnids = val\n",
    "        \n",
    "    @property\n",
    "    def vrange(self):\n",
    "        return self._vrange\n",
    "    \n",
    "    @vrange.setter\n",
    "    def vrange(self, val):\n",
    "        self.vnames = val.columns.to_list()\n",
    "        self._vrange = val\n",
    "    \n",
    "    @vrange.deleter\n",
    "    def vrange(self):\n",
    "        del self._vrange\n",
    "        print(\"dgenerator-35: self._vrange has been deleted.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def series_to_supervised(data, n_in=1, n_out=1, t2last=None, dropnan=True, vnames=None):\n",
    "\n",
    "        '''\n",
    "            convert series to supervised learning\n",
    "            \n",
    "            create a dataset with columns t - n_in, ..., t - 2, t - 1, t, t + 1, ..., t + (n_out - 1),\n",
    "            ex. if n_in = 2 and n_out = 2, then get a dataset with columns t - 2, t - 1, t, t + 1\n",
    "            \n",
    "            t2last: move current t + t2last to the last position, t2last can be negative,\n",
    "            ex. if n_in = 2, n_out = 3 and t2last = 0, then get a dataset with columns t - 2, t - 1, t + 1, t + 2, t\n",
    "            i.e. move t + t2last (= t + 0) to the last column \n",
    "            \n",
    "            vnames: column names\n",
    "        '''\n",
    "\n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            df = data\n",
    "        else:\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "        cols, names = list(), list()\n",
    "\n",
    "        # input sequence (t-n_in, ..., t-1)\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            if vnames is not None and len(vnames) == n_vars:\n",
    "                names += [\"{0}(t-{1})\".format(vname, i) for vname in vnames]\n",
    "            else:\n",
    "                names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "        # forecast sequence (t, t+1, ..., t+n_out-1)\n",
    "        for i in range(0, n_out):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                if vnames is not None and len(vnames) == n_vars:\n",
    "                    names += [\"{0}(t)\".format(vname) for vname in vnames]\n",
    "                else:\n",
    "                    names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "            else:\n",
    "                if vnames is not None and len(vnames) == n_vars:\n",
    "                    names += [(\"{0}(t+{1})\".format(vname, i)) for vname in vnames]\n",
    "                else:\n",
    "                    names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "        \n",
    "        if t2last is not None:  # position of current t: n_in + 1 \n",
    "\n",
    "            if (n_in + 1) + t2last >= n_in + n_out or (n_in + 1) + t2last <= 0:\n",
    "                pnsymbol = \"+\"\n",
    "                if t2last < 0:\n",
    "                    pnsymbol = \"-\"\n",
    "                logging.warning(\"can not or need not move t {} {} to the last position\".format(pnsymbol, abs(t2last)))\n",
    "            else:\n",
    "                moved = []\n",
    "                for i in range(n_vars):\n",
    "    #                 j = (n_out - 1) * n_vars + i\n",
    "                    j = ((n_in + 1) + t2last - 1) * n_vars + i\n",
    "                    logging.debug(\"column indexes swap i = {}, j = {}\".format((-1) * n_vars + i, j))\n",
    "                    moved.append(names[j])\n",
    "\n",
    "                [names.remove(item) for item in moved]\n",
    "                names.extend(moved)\n",
    "                agg = agg.reindex(columns=names)\n",
    "        \n",
    "        # drop rows with NaN values\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "        return agg\n",
    "            \n",
    "    @staticmethod\n",
    "    def mdfinspector(ind, cwbfmt, autofmt, tperiod=None, qc_log=None, cmpltd=None, rtqc=False):\n",
    "\n",
    "        '''\n",
    "            check what time do mdf exist \n",
    "            cwbfmt: suffix of filename\n",
    "            autofmt: suffix of filename\n",
    "            tperiod: time period for inspecting mdf, a list like [stime, etime], fmt: YmdHM\n",
    "            qc_log: fid (open file object) for log\n",
    "            cmpltd: \n",
    "            rtqc: if True, only check datetime within recent 24 hours;\n",
    "        '''\n",
    "        \n",
    "        if cmpltd is None:\n",
    "            cmpltd = ind\n",
    "        \n",
    "        if tperiod is not None:\n",
    "            if len(tperiod) == 1:\n",
    "                qc_stime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                qc_etime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                tperiod.append(tperiod[0])\n",
    "            elif len(tperiod) == 2:\n",
    "                qc_stime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                qc_etime = datetime.strptime(str(tperiod[1]), \"%Y%m%d%H%M\")\n",
    "            else:\n",
    "                tperiod = None\n",
    "                print(\"Warning-mdfinspector-178: time period is a list with length 2.\")\n",
    "                \n",
    "        if tperiod is None:\n",
    "            qc_stime = datetime.now() - timedelta(years=30)\n",
    "            qc_etime = datetime.now()\n",
    "\n",
    "        fnames = os.listdir(ind)\n",
    "        fnames.sort()\n",
    "\n",
    "        cwbfre = re.compile(pattern=r\"^([0-9]{10})([0-9]{2})\" + cwbfmt)\n",
    "        autofre = re.compile(pattern=r\"^([0-9]{10})([0-9]{2})\" + autofmt)\n",
    "\n",
    "        qcdtimes  = []  # an integer list\n",
    "\n",
    "        dtnow = datetime.now()\n",
    "\n",
    "        # check if cwb or auto exists (one of them)\n",
    "        nf = 0\n",
    "        for idx, tmp in enumerate(fnames):\n",
    "\n",
    "            autofmatch = autofre.match(tmp)\n",
    "            cwbfmatch = cwbfre.match(tmp)\n",
    "            matched = False\n",
    "            dtobj = None\n",
    "\n",
    "            if autofmatch is not None:\n",
    "                YYYYmmddHHMM = autofmatch.group(1) + autofmatch.group(2)\n",
    "                if int(YYYYmmddHHMM) not in qcdtimes:\n",
    "                    if os.path.isfile(\"{}/{}{}\".format(ind, YYYYmmddHHMM, cwbfmt)) or os.path.isfile(\"{}/{}{}\".format(cmpltd, YYYYmmddHHMM, cwbfmt)):  # check cwb\n",
    "                        dtobj = datetime.strptime(YYYYmmddHHMM, \"%Y%m%d%H%M\")\n",
    "            elif cwbfmatch is not None:\n",
    "                YYYYmmddHHMM = cwbfmatch.group(1) + cwbfmatch.group(2)\n",
    "                if int(YYYYmmddHHMM) not in qcdtimes:\n",
    "                    if os.path.isfile(\"{}/{}{}\".format(ind, YYYYmmddHHMM, autofmt)) or os.path.isfile(\"{}/{}{}\".format(cmpltd, YYYYmmddHHMM, autofmt)):  # check auto\n",
    "                        dtobj = datetime.strptime(YYYYmmddHHMM, \"%Y%m%d%H%M\")\n",
    "\n",
    "            if dtobj is not None:\n",
    "                if rtqc:\n",
    "                    if abs((dtnow - dtobj).total_seconds() / (60 * 60)) > (8 + 24):  # obs file is UTC time\n",
    "                        continue\n",
    "                    matched = True\n",
    "\n",
    "                if tperiod is not None:                                              # check qc time period\n",
    "                    if not (qc_stime <= dtobj and dtobj <= qc_etime):\n",
    "                        continue\n",
    "                    matched = True\n",
    "\n",
    "                if matched:\n",
    "                    qcdtimes.append(int(YYYYmmddHHMM))\n",
    "                    if qc_log is not None:\n",
    "                        nf += 1\n",
    "                        qc_log.write(\"  {0:3d}. {1}\\n\".format(nf, YYYYmmddHHMM + cwbfmt))\n",
    "                        nf += 1\n",
    "                        qc_log.write(\"  {0:3d}. {1}\\n\".format(nf, YYYYmmddHHMM + autofmt))\n",
    "\n",
    "        return sorted(set(qcdtimes))\n",
    "    \n",
    "    \n",
    "    def hrfgenerator(self, tperiod, n_in=6, n_out=1, t2last=0, mode=\"train\", fnpy=True, \n",
    "                     rescale=True, reformat=True, vstack=True, dropnan=True, classify=None, generator=False, batchsize=32):\n",
    "        \n",
    "        '''\n",
    "            need hrf in textloader module\n",
    "            {mode} is just suffix of npy files, ex. mdf_{mode}.npy, qcdtime_{mode}.npy, stnid_{mode}.npy\n",
    "            if {fnpy} is True, then load data from npy files\n",
    "            if {generator} is True, then {batchesize} will be activated and get a iterator (generator)\n",
    "            if {rescale} is True, then data will be normalized (StandardScaler). \n",
    "            if {rescale} is \"MinMax\", then use MinMaxScaler.\n",
    "            if {reformat} is True, then data array will be reformatted by staticmethod \"series_to_supervised\" with arguments {n_in}, {n_out}\n",
    "            if {vstack} is True, then observations of all stations (dim = (nsize, :)) will stack vertically (dim = (nsize * nstn, :))\n",
    "            if {dropnan} is True, then data less than minimum in self.vrange will be set to np.nan and dropped if {vstack} is True\n",
    "        '''\n",
    "        \n",
    "        ind        = self.ind\n",
    "        npyd       = self.npyd\n",
    "        stnids     = self.stnids\n",
    "        nstn       = self.nstn\n",
    "        vnames     = self.vnames\n",
    "        vrange     = self.vrange\n",
    "#         vnames_    = vrange.columns.tolist()\n",
    "        vname2abbr = self.vname2abbr\n",
    "\n",
    "#         assert vnames == vnames_\n",
    "        \n",
    "        logging.info(\"hrfgenerator-vnames-199: {}\".format(vnames))\n",
    "\n",
    "        if tperiod is not None:\n",
    "            if len(tperiod) == 1:\n",
    "                sdtime = tperiod[0]\n",
    "                edtime = tperiod[0]\n",
    "                tperiod.append(tperiod[0])\n",
    "            elif len(tperiod) == 2:\n",
    "                sdtime = tperiod[0]\n",
    "                edtime = tperiod[1]\n",
    "            else:\n",
    "                tperiod = None\n",
    "                logging.error(\"tperiod is None\")\n",
    "                sys.exit(-1)    \n",
    "\n",
    "        if fnpy:\n",
    "            if npyd is None:  \n",
    "                logging.error(\"npyd is None\")\n",
    "                sys.exit(-1)\n",
    "                \n",
    "            darray   = np.load(\"{}/hrf_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode))\n",
    "            qcdtimes = np.load(\"{}/qcdtime_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), allow_pickle=True).tolist()\n",
    "            _stnids  = np.load(\"{}/stnid_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), allow_pickle=True).tolist()\n",
    "            nsize    = len(qcdtimes)\n",
    "            _nstn    = len(_stnids)\n",
    "            \n",
    "            if stnids is not None:\n",
    "                assert stnids == _stnids\n",
    "            else:\n",
    "                stnids = _stnids\n",
    "            \n",
    "            if nstn is not None:\n",
    "                assert nstn == _nstn\n",
    "            else:\n",
    "                nstn = _nstn\n",
    "                \n",
    "            assert darray.shape[2] == len(vnames)            \n",
    "            logging.debug(\"inf={}/hrf_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode))\n",
    "            logging.debug(\"darray.shape={}, nsize={}, nstn={}\".format(darray.shape, nsize, _nstn))\n",
    "\n",
    "        else:\n",
    "            # load hrf and output to npy (if npyd is not None)\n",
    "            \n",
    "            if stnids is None or nstn is None:\n",
    "                logging.error(\"stnids or nstn is None.\")\n",
    "                sys.exit(-1)\n",
    "            \n",
    "            obs = []\n",
    "\n",
    "            for _vname in vnames:\n",
    "                vname = vname2abbr[_vname] if _vname in vname2abbr.keys() else _vname\n",
    "                _ind = \"{0}/{1}\".format(ind, vname)\n",
    "                _obs, stnid, _YYYYmmddHH, quantity = textloader.hrf(_ind, stnids, sdtime, edtime, hrfp=\"hr_{}\".format(vname.lower()))\n",
    "                logging.info(\"quantity of {}: {}\".format(vname, quantity))\n",
    "                YYYYmmddHH = _YYYYmmddHH\n",
    "                obs.append(_obs.T)\n",
    "            \n",
    "            darray   = np.stack(obs, axis=2)  # [nsize, nstn, # of vnames]\n",
    "            nsize    = darray.shape[0]\n",
    "            nstn     = darray.shape[1]\n",
    "            qcdtimes = YYYYmmddHH\n",
    "            stnids   = stnid\n",
    "            \n",
    "            if npyd is not None:\n",
    "                np.save(\"{}/hrf_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=darray)\n",
    "                np.save(\"{}/qcdtime_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=np.array(qcdtimes))\n",
    "                np.save(\"{}/stnid_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=np.array(stnids))\n",
    "                \n",
    "        return dgenerator._dprocessing(darray, qcdtimes, stnids, vrange, n_in=n_in, n_out=n_out, t2last=t2last, batchsize=batchsize, rescale=rescale, reformat=reformat, vstack=vstack, dropnan=dropnan, generator=generator, classify=classify)\n",
    "\n",
    "    \n",
    "    def mdfgenerator(self, tperiod, n_in=6, n_out=1, t2last=0, mode=\"train\", fnpy=True, \n",
    "                     rescale=True, reformat=True, vstack=True, dropnan=True, classify=None, generator=False, batchsize=32):\n",
    "\n",
    "        '''\n",
    "            {mode} is just suffix of npy files, ex. mdf_{mode}.npy, qcdtime_{mode}.npy, stnid_{mode}.npy\n",
    "            if {fnpy} is True, then load data from npy files\n",
    "            if {generator} is True, then {batchesize} will be activated and get a iterator (generator)\n",
    "            if {rescale} is True, then data will be normalized (StandardScaler). \n",
    "            if {rescale} is \"MinMax\", then use MinMaxScaler.\n",
    "            if {reformat} is True, then data array will be reformatted by staticmethod \"series_to_supervised\" with arguments {n_in}, {n_out}\n",
    "            if {vstack} is True, then observations of all stations (dim = (nsize, :)) will stack vertically (dim = (nsize * nstn, :))\n",
    "            if {dropnan} is True, then data less than minimum in self.vrange will be set to np.nan and dropped if {vstack} is True\n",
    "        '''\n",
    "        \n",
    "        ind     = self.ind\n",
    "        cmpltd  = self.cmpltd\n",
    "        npyd    = self.npyd\n",
    "        parsed  = self.parsed\n",
    "        cwbfmt  = self.cwbfmt \n",
    "        autofmt = self.autofmt \n",
    "        pfmt    = self.pfmt\n",
    "        stnids  = self.stnids\n",
    "        nstn    = self.nstn\n",
    "        vnames  = self.vnames\n",
    "        vrange  = self.vrange\n",
    "\n",
    "        colname = [\"Temp\", \"RH\", \"Pres\", \"Precp\"]\n",
    "        \n",
    "        logging.info(\"{}\".format(vnames))\n",
    "        \n",
    "        if tperiod is not None:\n",
    "            if len(tperiod) == 1:\n",
    "                sdtime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                edtime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                tperiod.append(tperiod[0])\n",
    "            elif len(tperiod) == 2:\n",
    "                sdtime = datetime.strptime(str(tperiod[0]), \"%Y%m%d%H%M\")\n",
    "                edtime = datetime.strptime(str(tperiod[1]), \"%Y%m%d%H%M\")\n",
    "            else:\n",
    "                tperiod = None\n",
    "                logging.error(\"tperiod is None.\")\n",
    "                sys.exit(-1)\n",
    "\n",
    "        if fnpy:  # data from npy\n",
    "            \n",
    "            if npyd is None:  \n",
    "                logging.error(\"npyd is None.\")\n",
    "                sys.exit(-1)\n",
    "                \n",
    "            darray   = np.load(\"{}/mdf_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode))\n",
    "            qcdtimes = np.load(\"{}/qcdtime_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), allow_pickle=True).tolist()\n",
    "            _stnids  = np.load(\"{}/stnid_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), allow_pickle=True).tolist()\n",
    "            \n",
    "            nsize = len(qcdtimes)\n",
    "            _nstn = len(_stnids)  # it's a list\n",
    "            \n",
    "            if stnids is not None:\n",
    "                assert stnids == _stnids\n",
    "            else:\n",
    "                stnids = _stnids\n",
    "                \n",
    "            if nstn is not None:\n",
    "                assert nstn == _nstn\n",
    "            else:\n",
    "                nstn = _nstn\n",
    "                \n",
    "            assert darray.shape[2] == len(vnames)\n",
    "            \n",
    "        else:    \n",
    "            if stnids is None or nstn is None:\n",
    "                logging.error(\"stnids or nstn is None.\")\n",
    "                sys.exit(-1)\n",
    "\n",
    "            syr = sdtime.timetuple()[0]\n",
    "            qcdtimes, idx2posi = dtimeGenerator([tperiod[0], tperiod[1]], fmt=\"%Y%m%d%H%M\")\n",
    "#             qcdtimes_ = dgenerator.mdfinspector(ind, cwbfmt, autofmt, tperiod=tperiod)\n",
    "            nsize = len(qcdtimes)\n",
    "            \n",
    "            darray = np.ndarray(shape=(nsize, nstn, 4))  # Temp, RH, Pres, Precp\n",
    "            darray.fill(-999)\n",
    "        \n",
    "            dtime_ = sdtime\n",
    "            counts = 0\n",
    "            jobs = []\n",
    "            jnames = []\n",
    "\n",
    "            while dtime_ <= edtime:\n",
    "                dtime = dtime_.strftime(\"%Y%m%d%H%M\")\n",
    "                counts += 1\n",
    "                jnames.append(\"{0:>04d}-{1}\".format(counts, dtime))\n",
    "                jobs.append([qcfparser, [dtime, [ind, cmpltd, parsed]], {\"outdir\": parsed}])  # don't output if outdir is None\n",
    "                if dtime_ == edtime:\n",
    "                    ret = runFunctionsInParallel(jobs, names=jnames, \n",
    "                                                 offsetsSeconds=0, maxAtOnce=None, \n",
    "                                                 parallel=True, allowJobFailure=True)\n",
    "                    for qidx in range(counts):\n",
    "                        id_     = ret[1][qidx][0]\n",
    "                        array_  = ret[1][qidx][1]\n",
    "                        chname_ = ret[1][qidx][2]\n",
    "                        dt_     = ret[1][qidx][3]\n",
    "                        ttuple_  = datetime.strptime(dt_, \"%Y%m%d%H%M\").timetuple()\n",
    "                        if array_ is None:  # to take obs from parsed files in order to make a time series is continuous\n",
    "                            pdarray = floader(parsed, \"{}{}\".format(dt_, pfmt))\n",
    "                            if pdarray is None:\n",
    "                                logging.warning(\"mdfgenerator-363: why array_ is None on {}?\".format(dt_))\n",
    "                                continue\n",
    "                            id_     = pdarray[0:, 0]\n",
    "                            array_  = pdarray[0:, 1:-1]\n",
    "                            chname_ = pdarray[0:, -1]\n",
    "\n",
    "#                         dt_idx = idx2posi[ttuple_[0] - syr, ttuple_[7], ttuple_[3], int(ttuple_[4] * 0.1)]\n",
    "                        dt_idx = idx2posi[ttuple_[0] - syr, ttuple_[7] - 1, ttuple_[3] - 1, int(ttuple_[4] * 0.1)]\n",
    "\n",
    "                        logging.debug(\"ttuple: {}, idx: {}\".format(ttuple_, dt_idx))\n",
    "                        for wrow, mdfid in enumerate(id_):\n",
    "\n",
    "                            if not (mdfid in stnids):\n",
    "                               continue\n",
    "\n",
    "                            id_idx = stnids.index(mdfid)\n",
    "                            \n",
    "#                             dt_idx = qcdtimes.index(int(dt_))\n",
    "\n",
    "                            darray[dt_idx, id_idx, 0] = float(array_[wrow, 3])  # Temp\n",
    "                            darray[dt_idx, id_idx, 1] = float(array_[wrow, 4])  # RH\n",
    "                            darray[dt_idx, id_idx, 2] = float(array_[wrow, 5])  # Pres\n",
    "                            darray[dt_idx, id_idx, 3] = float(array_[wrow, 6])  # Precp\n",
    "\n",
    "                    counts = 0\n",
    "                    jobs = []\n",
    "                    jnames = []\n",
    "\n",
    "                dtime_ = dtime_ + timedelta(minutes=10)\n",
    "\n",
    "            if len(vnames) < len(colname):\n",
    "                v2idx = [colname.index(i) for i in vnames]                \n",
    "                darray = np.delete(darray, obj=np.setdiff1d(np.arange(len(colname)), np.array(v2idx)), axis=2)\n",
    "\n",
    "            if npyd is not None:\n",
    "                np.save(\"{}/mdf_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=darray)\n",
    "                np.save(\"{}/qcdtime_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=np.array(qcdtimes))\n",
    "                np.save(\"{}/stnid_{}_{}_{}.npy\".format(npyd, tperiod[0], tperiod[1], mode), arr=np.array(stnids))        \n",
    "                \n",
    "        return dgenerator._dprocessing(darray, qcdtimes, stnids, vrange, n_in=n_in, n_out=n_out, t2last=t2last, batchsize=batchsize, rescale=rescale, reformat=reformat, vstack=vstack, dropnan=dropnan, generator=generator, classify=classify)\n",
    "            \n",
    "    @staticmethod            \n",
    "    def _dprocessing(darray, qcdtimes, stnids, vrange, n_in=6, n_out=1, t2last=0, batchsize=32, rescale=None, reformat=True, vstack=True, dropnan=True, generator=False, classify=None):\n",
    "        \n",
    "        '''\n",
    "            - darray.shape = (nsize, nstn, nfeature (# of vnames, ex. Temp, Pres, RH, Precp, ...))\n",
    "            \n",
    "            - darray[:, :, idx]\n",
    "            \n",
    "                idx       |    0 |  1 |    2 |     3\n",
    "             ------------------------------------------\n",
    "                variable  | Temp | RH | Pres | Precp\n",
    "                \n",
    "                \n",
    "            - classify: [[idx1, idx2, ...], [[values for classifing], [], ...]]\n",
    "            ex.\n",
    "                [[0, 3], [[-5, 0, 5, 10, 15], [0, 10, 20, 30, 40]]]\n",
    "                0 to Temp, 3 to Precp\n",
    "            \n",
    "            - t2last: swap columns of idx=t+t2last and idx=-1\n",
    "            - dropnan works only vstack=True\n",
    "        '''\n",
    "        \n",
    "        vnames   = vrange.columns.to_list()\n",
    "        nsize    = len(qcdtimes)\n",
    "        nstn     = len(stnids)\n",
    "        nfeature = len(vnames)\n",
    "        \n",
    "        if dropnan:\n",
    "            for idx, vname in enumerate(vnames):\n",
    "                logging.info(\"drop missing values of {} ({}, {})\".format(vname, vrange.iloc[0][vname], vrange.iloc[1][vname]))\n",
    "                darray[:, :, idx][np.where(darray[:, :, idx] < vrange.loc[0][vname])] = np.nan           \n",
    "\n",
    "        ##############################\n",
    "        ### classify by values\n",
    "        ##############################\n",
    "        if classify is not None:\n",
    "            \n",
    "            vidx = classify[0]\n",
    "            byv  = classify[1] \n",
    "            clsarray = np.ndarray((nsize, nstn, nfeature), dtype=np.int32)\n",
    "            clsarray.fill(-999)\n",
    "            \n",
    "            for _idx, _vidx in enumerate(vidx):\n",
    "                for id_idx in range(nstn):\n",
    "                    for which_class, _v in enumerate(byv[_idx]):\n",
    "                        _d = darray[:, id_idx, _vidx]\n",
    "                        if which_class == 0:\n",
    "                            clsarray[np.where(_d <= _v), id_idx, _vidx] = which_class\n",
    "                            if which_class == len(byv[_idx]) - 1:  # for only 2 classes\n",
    "                                clsarray[np.where(_d > _v), id_idx, _vidx] = which_class + 1\n",
    "                        elif which_class == len(byv[_idx]) - 1:\n",
    "                            clsarray[np.where((_d > byv[_idx][which_class - 1]) & (_d <= _v)), id_idx, _vidx] = which_class\n",
    "                            clsarray[np.where(_d > _v), id_idx, _vidx] = which_class + 1\n",
    "                        else:\n",
    "                            clsarray[np.where((_d > byv[_idx][which_class - 1]) & (_d <= _v)), id_idx, _vidx] = which_class\n",
    "                 \n",
    "        ts2supervise = np.copy(darray)  # dim = [nsize, nstn, 4]\n",
    "        \n",
    "        ##############################\n",
    "        ### rescale or normalize\n",
    "        ##############################\n",
    "        rescaled = []        \n",
    "        if rescale is not None:\n",
    "            if rescale == \"MinMax\":\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                scaler.fit(vrange.values)\n",
    "            else:\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                scaler.fit(np.reshape(darray, (nsize * nstn, nfeature)))\n",
    "                \n",
    "            for id_idx, _id in enumerate(stnids):\n",
    "                rescaled.append(scaler.transform(darray[:, id_idx, :]))\n",
    "                \n",
    "            ts2supervise = np.stack(rescaled, axis=1)  # dim = [nsize, nstn, nfeature]\n",
    "            logging.debug(\"ts2supervise.shape = {} (rescaled)\".format(ts2supervise.shape))\n",
    "        else:    \n",
    "            scaler = None\n",
    "            for id_idx, _id in enumerate(stnids):\n",
    "                rescaled.append(darray[:, id_idx, :])\n",
    "        \n",
    "        ###########################\n",
    "        ### series to supervised\n",
    "        ###########################\n",
    "        reformated = []\n",
    "        if reformat:\n",
    "            for id_idx, _id in enumerate(stnids):\n",
    "                reformated.append(dgenerator.series_to_supervised(rescaled[id_idx], n_in=n_in, n_out=n_out, t2last=t2last, dropnan=False, vnames=vnames).values)  # dim(rescaled[id_idx]) = [nsize, (n_in + n_out) * nfeature]\n",
    "         \n",
    "            if vstack:\n",
    "                \n",
    "                if classify is not None:\n",
    "                    clslist = []\n",
    "                    for id_idx, _id in enumerate(stnids):\n",
    "                        clslist.append(clsarray[:, id_idx, :])\n",
    "                    clsarray = np.vstack(clslist)  # dim = [nsize * nstn, nfeature]\n",
    "                \n",
    "                ts2supervise = np.vstack(reformated)  # dim = [nsize * nstn, (n_in + n_out) * nfeature]\n",
    "\n",
    "                if dropnan:\n",
    "                    if classify is not None:\n",
    "                        clsarray = clsarray[~np.isnan(ts2supervise).any(axis=1)]\n",
    "                    ts2supervise = ts2supervise[~np.isnan(ts2supervise).any(axis=1)]\n",
    "                    \n",
    "                    if classify is not None:\n",
    "                        logging.debug(\"shape of ts2supervise: {}, clsarray: {}, {}\".format(ts2supervise.shape, clsarray.shape, ts2supervise[~np.isnan(ts2supervise).any(axis=1)].shape))\n",
    "                    else:\n",
    "                        logging.debug(\"shape of ts2supervise: {}\".format(ts2supervise.shape))\n",
    "\n",
    "                _nsize = ts2supervise.shape[0]\n",
    "\n",
    "            else:\n",
    "                ts2supervise = np.stack(reformated, axis=1)  # dim = [nsize, nstn, (n_in + n_out) * nfeature]\n",
    "                _nsize = nsize\n",
    "        \n",
    "            logging.debug(\"ts2supervise.shape = {} (reformated)\".format(ts2supervise.shape))\n",
    "\n",
    "        def _diterator():\n",
    "            # variables can still identify in this function scope\n",
    "            while True:\n",
    "                idx = np.random.choice(_nsize, batchsize, replace=False)\n",
    "                if reformat:\n",
    "                    if vstack:\n",
    "                        yield ts2supervise[idx, :((-nfeature) * n_out)], ts2supervise[idx, ((-nfeature) * n_out):]\n",
    "                    else:\n",
    "                        yield ts2supervise[idx, :, :((-nfeature) * n_out)], ts2supervise[idx, :, ((-nfeature) * n_out):]\n",
    "\n",
    "        if not generator:\n",
    "            if classify is not None:\n",
    "                return [ts2supervise, clsarray, qcdtimes, stnids, darray, scaler]\n",
    "\n",
    "            return [ts2supervise, qcdtimes, stnids, darray, scaler]\n",
    "        else:\n",
    "            logging.info(\"data generator has been built.\")\n",
    "            return _diterator()\n",
    "        \n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T06:28:54.071546Z",
     "iopub.status.busy": "2021-03-16T06:28:54.071312Z",
     "iopub.status.idle": "2021-03-16T06:28:54.113263Z",
     "shell.execute_reply": "2021-03-16T06:28:54.112779Z",
     "shell.execute_reply.started": "2021-03-16T06:28:54.071522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "raw data\n",
      "         Temp          Pres         RH\n",
      "0  162.842100  -6048.222092 -10.539357\n",
      "1   25.017026   1101.345123   2.300198\n",
      "2  153.225027   4655.838388   0.333822\n",
      "3  128.819018  -3812.838241 -15.935867\n",
      "4  178.664745   5889.682241 -20.846992\n",
      "5   -2.945290   9070.724088  10.470045\n",
      "6   24.073500   -416.062304   5.025151\n",
      "7 -141.370763 -19629.371313  19.132778\n",
      "8 -143.515371   5712.796138  -4.864028\n",
      "9   78.792101    816.525768  -4.211838\n",
      "========================================================================\n",
      "series_to_supervised\n",
      "    Temp(t-6)    Pres(t-6)    RH(t-6)   Temp(t-5)    Pres(t-5)    RH(t-5)  \\\n",
      "0         NaN          NaN        NaN         NaN          NaN        NaN   \n",
      "1         NaN          NaN        NaN         NaN          NaN        NaN   \n",
      "2         NaN          NaN        NaN         NaN          NaN        NaN   \n",
      "3         NaN          NaN        NaN         NaN          NaN        NaN   \n",
      "4         NaN          NaN        NaN         NaN          NaN        NaN   \n",
      "5         NaN          NaN        NaN  162.842100 -6048.222092 -10.539357   \n",
      "6  162.842100 -6048.222092 -10.539357   25.017026  1101.345123   2.300198   \n",
      "7   25.017026  1101.345123   2.300198  153.225027  4655.838388   0.333822   \n",
      "8  153.225027  4655.838388   0.333822  128.819018 -3812.838241 -15.935867   \n",
      "9  128.819018 -3812.838241 -15.935867  178.664745  5889.682241 -20.846992   \n",
      "\n",
      "    Temp(t-4)    Pres(t-4)    RH(t-4)   Temp(t-3)  ...    RH(t-3)   Temp(t-2)  \\\n",
      "0         NaN          NaN        NaN         NaN  ...        NaN         NaN   \n",
      "1         NaN          NaN        NaN         NaN  ...        NaN         NaN   \n",
      "2         NaN          NaN        NaN         NaN  ...        NaN  162.842100   \n",
      "3         NaN          NaN        NaN  162.842100  ... -10.539357   25.017026   \n",
      "4  162.842100 -6048.222092 -10.539357   25.017026  ...   2.300198  153.225027   \n",
      "5   25.017026  1101.345123   2.300198  153.225027  ...   0.333822  128.819018   \n",
      "6  153.225027  4655.838388   0.333822  128.819018  ... -15.935867  178.664745   \n",
      "7  128.819018 -3812.838241 -15.935867  178.664745  ... -20.846992   -2.945290   \n",
      "8  178.664745  5889.682241 -20.846992   -2.945290  ...  10.470045   24.073500   \n",
      "9   -2.945290  9070.724088  10.470045   24.073500  ...   5.025151 -141.370763   \n",
      "\n",
      "      Pres(t-2)    RH(t-2)   Temp(t-1)     Pres(t-1)    RH(t-1)     Temp(t)  \\\n",
      "0           NaN        NaN         NaN           NaN        NaN  162.842100   \n",
      "1           NaN        NaN  162.842100  -6048.222092 -10.539357   25.017026   \n",
      "2  -6048.222092 -10.539357   25.017026   1101.345123   2.300198  153.225027   \n",
      "3   1101.345123   2.300198  153.225027   4655.838388   0.333822  128.819018   \n",
      "4   4655.838388   0.333822  128.819018  -3812.838241 -15.935867  178.664745   \n",
      "5  -3812.838241 -15.935867  178.664745   5889.682241 -20.846992   -2.945290   \n",
      "6   5889.682241 -20.846992   -2.945290   9070.724088  10.470045   24.073500   \n",
      "7   9070.724088  10.470045   24.073500   -416.062304   5.025151 -141.370763   \n",
      "8   -416.062304   5.025151 -141.370763 -19629.371313  19.132778 -143.515371   \n",
      "9 -19629.371313  19.132778 -143.515371   5712.796138  -4.864028   78.792101   \n",
      "\n",
      "        Pres(t)      RH(t)  \n",
      "0  -6048.222092 -10.539357  \n",
      "1   1101.345123   2.300198  \n",
      "2   4655.838388   0.333822  \n",
      "3  -3812.838241 -15.935867  \n",
      "4   5889.682241 -20.846992  \n",
      "5   9070.724088  10.470045  \n",
      "6   -416.062304   5.025151  \n",
      "7 -19629.371313  19.132778  \n",
      "8   5712.796138  -4.864028  \n",
      "9    816.525768  -4.211838  \n",
      "\n",
      "[10 rows x 21 columns]\n",
      "========================================================================\n",
      "series_to_supervised\n",
      "    Temp(t-2)     Pres(t-2)    RH(t-2)   Temp(t-1)     Pres(t-1)    RH(t-1)  \\\n",
      "0         NaN           NaN        NaN         NaN           NaN        NaN   \n",
      "1         NaN           NaN        NaN  162.842100  -6048.222092 -10.539357   \n",
      "2  162.842100  -6048.222092 -10.539357   25.017026   1101.345123   2.300198   \n",
      "3   25.017026   1101.345123   2.300198  153.225027   4655.838388   0.333822   \n",
      "4  153.225027   4655.838388   0.333822  128.819018  -3812.838241 -15.935867   \n",
      "5  128.819018  -3812.838241 -15.935867  178.664745   5889.682241 -20.846992   \n",
      "6  178.664745   5889.682241 -20.846992   -2.945290   9070.724088  10.470045   \n",
      "7   -2.945290   9070.724088  10.470045   24.073500   -416.062304   5.025151   \n",
      "8   24.073500   -416.062304   5.025151 -141.370763 -19629.371313  19.132778   \n",
      "9 -141.370763 -19629.371313  19.132778 -143.515371   5712.796138  -4.864028   \n",
      "\n",
      "    Temp(t+1)     Pres(t+1)    RH(t+1)   Temp(t+2)     Pres(t+2)    RH(t+2)  \\\n",
      "0   25.017026   1101.345123   2.300198  153.225027   4655.838388   0.333822   \n",
      "1  153.225027   4655.838388   0.333822  128.819018  -3812.838241 -15.935867   \n",
      "2  128.819018  -3812.838241 -15.935867  178.664745   5889.682241 -20.846992   \n",
      "3  178.664745   5889.682241 -20.846992   -2.945290   9070.724088  10.470045   \n",
      "4   -2.945290   9070.724088  10.470045   24.073500   -416.062304   5.025151   \n",
      "5   24.073500   -416.062304   5.025151 -141.370763 -19629.371313  19.132778   \n",
      "6 -141.370763 -19629.371313  19.132778 -143.515371   5712.796138  -4.864028   \n",
      "7 -143.515371   5712.796138  -4.864028   78.792101    816.525768  -4.211838   \n",
      "8   78.792101    816.525768  -4.211838         NaN           NaN        NaN   \n",
      "9         NaN           NaN        NaN         NaN           NaN        NaN   \n",
      "\n",
      "      Temp(t)       Pres(t)      RH(t)  \n",
      "0  162.842100  -6048.222092 -10.539357  \n",
      "1   25.017026   1101.345123   2.300198  \n",
      "2  153.225027   4655.838388   0.333822  \n",
      "3  128.819018  -3812.838241 -15.935867  \n",
      "4  178.664745   5889.682241 -20.846992  \n",
      "5   -2.945290   9070.724088  10.470045  \n",
      "6   24.073500   -416.062304   5.025151  \n",
      "7 -141.370763 -19629.371313  19.132778  \n",
      "8 -143.515371   5712.796138  -4.864028  \n",
      "9   78.792101    816.525768  -4.211838  \n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    sepl = \"========================================================================\"\n",
    "###### 1. series_to_supervised\n",
    "\n",
    "    n = 10\n",
    "    df = pd.DataFrame({'Temp': np.random.randn(n) * 100,\n",
    "                       'Pres': np.random.randn(n) * 10000,\n",
    "                       'RH': np.random.randn(n) * 10})\n",
    "    \n",
    "    print(sepl)\n",
    "    print(\"raw data\")\n",
    "    print(df)\n",
    "    print(sepl)\n",
    "#     pda = dgenerator.series_to_supervised(df, n_in=0, n_out=2, dropnan=False, vnames=['Temp', 'Pres', 'RH'])\n",
    "    pda = dgenerator.series_to_supervised(df, n_in=6, n_out=1, t2last=None, dropnan=False, vnames=['Temp', 'Pres', 'RH'])\n",
    "    print(\"series_to_supervised\")\n",
    "    print(pda)\n",
    "    print(sepl)\n",
    "    pda = dgenerator.series_to_supervised(df, n_in=2, n_out=3, t2last=0, dropnan=False, vnames=['Temp', 'Pres', 'RH'])\n",
    "    print(\"series_to_supervised\")\n",
    "    print(pda)\n",
    "    print(sepl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Temp  Pres    RH\n",
      "0    10  1200  0.84\n",
      "1    20  1132  0.77\n",
      "2    15   990  0.80\n",
      "3    30   993  0.75\n",
      "4    45  1034  0.52\n",
      "   Temp(t-2)  Pres(t-2)  RH(t-2)  Temp(t-1)  Pres(t-1)  RH(t-1)  Temp(t)  \\\n",
      "0        NaN        NaN      NaN        NaN        NaN      NaN       10   \n",
      "1        NaN        NaN      NaN       10.0     1200.0     0.84       20   \n",
      "2       10.0     1200.0     0.84       20.0     1132.0     0.77       15   \n",
      "3       20.0     1132.0     0.77       15.0      990.0     0.80       30   \n",
      "4       15.0      990.0     0.80       30.0      993.0     0.75       45   \n",
      "\n",
      "   Pres(t)  RH(t)  \n",
      "0     1200   0.84  \n",
      "1     1132   0.77  \n",
      "2      990   0.80  \n",
      "3      993   0.75  \n",
      "4     1034   0.52  \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "#     logging.getLogger().setLevel(logging.ERROR)\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    \n",
    "    npyd    = \"/home/yuzhe/DataScience/dataset\"\n",
    "\n",
    "    \n",
    "    #     stninfo = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/RR_analysis_grid_stationlist.txt\"\n",
    "    \n",
    "###### 1. series_to_supervised\n",
    "    df = pd.DataFrame({'Temp': [10, 20, 15, 30, 45],\n",
    "                       'Pres': [1200, 1132, 990, 993, 1034],\n",
    "                       'RH': [0.84, 0.77, 0.8, 0.75, 0.52]})\n",
    "    print(df)\n",
    "\n",
    "#     pda = dgenerator.series_to_supervised(df, n_in=0, n_out=2, dropnan=False, vnames=['Temp', 'Pres', 'RH'])\n",
    "    pda = dgenerator.series_to_supervised(df, n_in=2, n_out=1, dropnan=False, vnames=['Temp', 'Pres', 'RH'])\n",
    "\n",
    "    print(pda)\n",
    "    \n",
    "    sys.exit()\n",
    "                \n",
    "###### 2. vrange setter and vnames\n",
    "    vrange = {\"RH\": [0, 100]}\n",
    "    resd    = \"/NAS-DS1515P/users1/T1/res\"\n",
    "    ind    = \"/NAS-DS1515P/users1/realtimeQC/ftpdata\"\n",
    "    dg = dgenerator(resd=resd, ind=ind, npyd=npyd, vrange=vrange)\n",
    "\n",
    "###### 3. mdf\n",
    "    resd     = \"/NAS-DS1515P/users1/T1/res\"\n",
    "    ind      = \"/NAS-DS1515P/users1/realtimeQC/ftpdata\"\n",
    "    cmpltd   = ind\n",
    "#     tperiod  = [201801010100, 202007312350]\n",
    "    tperiod  = [202007310100, 202007310350]\n",
    "\n",
    "    parsed   = \"/home/yuzhe/DataScience/dataset/parsed\"\n",
    "    cwbfmt   = \".QPESUMS_STATION.10M.mdf\"\n",
    "    autofmt  = \".QPESUMS_STATION.15M.mdf\"\n",
    "    pfmt     = \".QPESUMS_STATION.txt\"\n",
    "    classify = [[3], [[0.1, 5, 10]]]\n",
    "    \n",
    "    mdfdg = dgenerator(gif=\"{}/stations.txt\".format(resd), ind=ind, npyd=npyd, cwbfmt=cwbfmt, autofmt=autofmt, pfmt=pfmt)\n",
    "#     mdfs = mdfdg.mdfgenerator(tperiod, n_in=6, n_out=1, mode=\"train\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=False, generator=False)            \n",
    "#     mdfs = mdfdg.mdfgenerator(tperiod, n_in=6, n_out=1, mode=\"train\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=False, generator=False, classify=classify)            \n",
    "    \n",
    "    mdfdg = dgenerator(gif=\"{}/stations.txt\".format(resd), ind=ind, npyd=None, cwbfmt=cwbfmt, autofmt=autofmt, pfmt=pfmt)\n",
    "#     mdfs = mdfdg.mdfgenerator(tperiod, n_in=6, n_out=1, mode=\"test\", rescale=\"MinMax\", reformat=True, vstack=False, fnpy=False, generator=False, classify=classify)            \n",
    "\n",
    "\n",
    "    #### 3.2 try only 3 features \n",
    "    tperiod  = [201801010100, 202007312350]\n",
    "    vrange = {\"Temp\": [-20.0, 50.0],\n",
    "              \"RH\": [0.0, 1.0],\n",
    "              \"Pres\": [600.0, 1100.0]}\n",
    "    classify = [[0, 2], [[5, 10, 15, 20], [600, 800, 1000]]]\n",
    "    \n",
    "    mdfdg = dgenerator(gif=\"{}/stations.txt\".format(resd), ind=ind, npyd=npyd, cwbfmt=cwbfmt, autofmt=autofmt, pfmt=pfmt)\n",
    "    mdfdg.vrange = pd.DataFrame(vrange)\n",
    "#     mdfs = mdfdg.mdfgenerator(tperiod, n_in=6, n_out=1, mode=\"train4temp\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=True, generator=False, classify=classify)            \n",
    "\n",
    "    #### 3.3 try only 1 features \n",
    "    tperiod  = [201801010100, 202007312350]\n",
    "    vrange = {\"Temp\": [-20.0, 50.0]}\n",
    "    classify = [[0], [[5, 10, 15, 20]]]\n",
    "\n",
    "    mdfdg = dgenerator(gif=\"{}/stations.txt\".format(resd), ind=ind, npyd=npyd, cwbfmt=cwbfmt, autofmt=autofmt, pfmt=pfmt)\n",
    "    mdfdg.vrange = pd.DataFrame(vrange)\n",
    "#     mdfs = mdfdg.mdfgenerator(tperiod, n_in=6, n_out=1, mode=\"temp\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=True, generator=False, classify=classify)            \n",
    "    \n",
    "    \n",
    "###### 4. hrf\n",
    "    ind      = \"/NAS-129/users1/T1/DATA/YY/ORG/HR1\"\n",
    "    npyd     = \"/home/yuzhe/DataScience/dataset\"\n",
    "    stninfo  = \"/home/yuzhe/CODE/ProgramT1/GRDTools/SRC/RES/GI/1500_decode_stationlist_without_space.txt\"\n",
    "\n",
    "#     classify = [[3], [[0.1, 5, 10, 20, 40]]]\n",
    "    \n",
    "    ### create object\n",
    "    hrfdg = dgenerator(ind=ind, gif=stninfo, npyd=npyd)\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"hourly\", rescale=\"MinMax\", reformat=True, vstack=False, fnpy=False, generator=False)\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"RHPrecpMinMax\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=False, generator=False)\n",
    "    \n",
    "    ### 4.1 hrf with 4 features  \n",
    "    vrange = {\"Temp\": [-20.0, 50.0],\n",
    "              \"RH\": [0.0, 100.0],\n",
    "              \"Pres\": [600.0, 1100.0],\n",
    "              \"Precp\": [0.0, 220.0]}\n",
    "    \n",
    "    hrfdg.vrange = pd.DataFrame(vrange)\n",
    "        \n",
    "    tperiod  = [1998010101, 2019123124]\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"hourly\", rescale=\"MinMax\", reformat=True, vstack=False, fnpy=False, generator=False)\n",
    "\n",
    "#     classify = [[0], [[5, 10, 15]]]\n",
    "#     vrange = {\"Temp\": [-20.0, 50.0]}\n",
    "#     hrfdg.vrange = pd.DataFrame(vrange)\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"hourly\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=True, generator=False, classify=classify)\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"hourlyTemp\", rescale=\"MinMax\", reformat=True, vstack=True, fnpy=True, generator=False)\n",
    "\n",
    "    tperiod  = [2016010101, 2018123124]\n",
    "#     hrfs = hrfdg.hrfgenerator(tperiod, n_in=6, n_out=1, mode=\"testMinMax\", rescale=\"MinMax\", reformat=True, vstack=False, fnpy=False, generator=False)\n",
    "\n",
    "    \n",
    "\n",
    "###### 5. check npy\n",
    "    arr = np.load(\"{}/mdf_201801010100_202007312350_train.npy\".format(npyd))\n",
    "#     qcdtimes = np.load(\"{}/qcdtime_201801010100_202007312350_train.npy\".format(npyd), allow_pickle=True)\n",
    "#     stnids = np.load(\"{}/stnid_201801010100_202007312350_train.npy\".format(npyd), allow_pickle=True)\n",
    "\n",
    "#     arr = arr[:, :, 0:-1]\n",
    "#     np.save(\"{}/mdf_201801010100_202007312350_train4temp.npy\".format(npyd), arr=arr)\n",
    "#     np.save(\"{}/qcdtime_201801010100_202007312350_train4temp.npy\".format(npyd), arr=qcdtimes)\n",
    "#     np.save(\"{}/stnid_201801010100_202007312350_train4temp.npy\".format(npyd), arr=stnids)\n",
    "\n",
    "#     arr = arr[:, :, 0]\n",
    "#     arr = arr[:, :, np.newaxis]\n",
    "#     np.save(\"{}/mdf_201801010100_202007312350_temp.npy\".format(npyd), arr=arr)\n",
    "#     np.save(\"{}/qcdtime_201801010100_202007312350_temp.npy\".format(npyd), arr=qcdtimes)\n",
    "#     np.save(\"{}/stnid_201801010100_202007312350_temp.npy\".format(npyd), arr=stnids)\n",
    "\n",
    "\n",
    "\n",
    "    # 5.3 hrf post processing\n",
    "    arr = np.load(\"{}/hrf_1998010101_2019123124_hourly.npy\".format(npyd))\n",
    "    qcdtimes = np.load(\"{}/qcdtime_1998010101_2019123124_hourly.npy\".format(npyd), allow_pickle=True)\n",
    "    stnids = np.load(\"{}/stnid_1998010101_2019123124_hourly.npy\".format(npyd), allow_pickle=True)\n",
    "\n",
    "    trainposi = np.where(qcdtimes < 2016010101)\n",
    "    np.save(\"{}/hrf_1998010101_2015123124_hourly.npy\".format(npyd), arr=arr[trainposi[0], :, :])\n",
    "    np.save(\"{}/qcdtime_1998010101_2015123124_hourly.npy\".format(npyd), arr=qcdtimes[trainposi[0]])\n",
    "    np.save(\"{}/stnid_1998010101_2015123124_hourly.npy\".format(npyd), arr=stnids)\n",
    "  \n",
    "    arr_ = arr[trainposi[0], :, 0]\n",
    "    arr_ = arr_[:, :, np.newaxis]\n",
    "    print(\"main-134: \", arr_.shape)\n",
    "    np.save(\"{}/hrf_1998010101_2015123124_hourlyTemp.npy\".format(npyd), arr=arr_)\n",
    "    np.save(\"{}/qcdtime_1998010101_2015123124_hourlyTemp.npy\".format(npyd), arr=qcdtimes[trainposi[0]])\n",
    "    np.save(\"{}/stnid_1998010101_2015123124_hourlyTemp.npy\".format(npyd), arr=stnids)\n",
    "  \n",
    "    \n",
    "    testposi = np.where(qcdtimes >= 2016010101)\n",
    "    np.save(\"{}/hrf_2016010101_2019123124_hourly.npy\".format(npyd), arr=arr[testposi[0], :, :])\n",
    "    np.save(\"{}/qcdtime_2016010101_2019123124_hourly.npy\".format(npyd), arr=qcdtimes[testposi[0]])\n",
    "    np.save(\"{}/stnid_2016010101_2019123124_hourly.npy\".format(npyd), arr=stnids)\n",
    "\n",
    "    arr_ = arr[testposi[0], :, 0]\n",
    "    arr_ = arr_[:, :, np.newaxis]\n",
    "    print(\"main-147: \", arr_.shape)\n",
    "    np.save(\"{}/hrf_2016010101_2019123124_hourlyTemp.npy\".format(npyd), arr=arr_)\n",
    "    np.save(\"{}/qcdtime_2016010101_2019123124_hourlyTemp.npy\".format(npyd), arr=qcdtimes[testposi[0]])\n",
    "    np.save(\"{}/stnid_2016010101_2019123124_hourlyTemp.npy\".format(npyd), arr=stnids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.0,    0.1],  0.914105 15932321 17429424\n",
      "(   0.1,    5.0],  0.073212 1276050 17429424\n",
      "(   5.0,   10.0],  0.006681 116439 17429424\n",
      "(  10.0,   20.0],  0.003885 67716 17429424\n",
      "(  20.0,   40.0],  0.001730 30151 17429424\n",
      "(  40.0,    inf),  0.000387 6747 17429424\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "###### check precp distribution\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    npyd = \"../dataset/hrf_2012010101_2015123124_trainMinMax.npy\"\n",
    "    hrd  = np.load(npyd)  # [nsize, nstn, 4]\n",
    "\n",
    "    precp = np.reshape(hrd[:, :, -1], (-1, 1))\n",
    "\n",
    "    v = [0.1, 5, 10, 20, 40,]\n",
    "    n = precp[np.where(precp >= 0)].shape[0]\n",
    "    for idx_, v_ in enumerate(v):\n",
    "        if idx_ == 0:\n",
    "            n_ = precp[np.where((0 <= precp) & (precp <= v_))].shape[0]\n",
    "            print(\"[{0:>6.1f}, {1:>6.1f}], {2:9.6f} {3} {4}\".format(0, v_, n_ / n, n_, n))\n",
    "        elif idx_ == len(v) - 1:\n",
    "            n_ = precp[np.where((v[idx_ - 1] < precp) & (precp <= v_))].shape[0]\n",
    "            print(\"({0:>6.1f}, {1:>6.1f}], {2:9.6f} {3} {4}\".format(v[idx_ - 1], v_, n_ / n, n_, n))\n",
    "            n_ = precp[np.where(v_ < precp)].shape[0]\n",
    "            print(\"({0:>6.1f},    inf), {1:9.6f} {2} {3}\".format(v_, n_ / n, n_, n))\n",
    "        else:\n",
    "            n_ = precp[np.where((v[idx_ - 1] < precp) & (precp <= v_))].shape[0]\n",
    "            print(\"({0:>6.1f}, {1:>6.1f}], {2:9.6f} {3} {4}\".format(v[idx_ - 1], v_, n_ / n, n_, n))\n",
    "\n",
    "            \n",
    "###### correlations\n",
    "\n",
    "    reformat = np.reshape(hrd, (-1, 4))\n",
    "    reformat[np.where(reformat < -90.)] = np.nan\n",
    "\n",
    "    df = pd.DataFrame(reformat, columns=[\"Temp\", \"RH\", \"Pres\", \"Precp\"])\n",
    "    corrMatrix = df.corr()\n",
    "    sns.heatmap(corrMatrix, annot=True, center=0, cmap=\"coolwarm\")\n",
    "\n",
    "######  pair plot\n",
    "\n",
    "#     idnpyd = \"../dataset/stnid_2012010101_2015123124_trainMinMax.npy\"\n",
    "#     stnids  = np.load(npyd)\n",
    "#     nstn = len(stnids)\n",
    "\n",
    "#     for idx, id_ in enumerate(stnids):\n",
    "#         df = hrd[:, idx, :]\n",
    "#         df = pd.DataFrame(df, columns=[\"Temp\", \"RH\", \"Pres\", \"Precp\"])\n",
    "#     #     g = pd.plotting.scatter_matrix(df, figsize=(10, 10), marker='o', hist_kwds={'bins': 10}, s=60, alpha=0.8)\n",
    "#         sns.pairplot(df)\n",
    "#         plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
